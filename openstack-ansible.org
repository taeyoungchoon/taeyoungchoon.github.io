* log, aio and Not enough space available with bootstrap_host_data_disk_min_size

https://stafwag.github.io/blog/blog/2019/01/21/settinp-up-openstack-ansible-all-in-one-on-a-centos-7-system/

[root@c71 openstack-ansible]# ./scripts/bootstrap-aio.sh

TASK [bootstrap-host : Fail if there is not enough space available in /] 
fatal: [localhost]: FAILED! => {"changed": false, "failed": true, "msg": "Not enough space available in /.\nFound 36.39 GB, required 50 GB)\n"}

# pwd
/opt/openstack-ansible/tests/roles/bootstrap-host/tasks
# ls check-requirements.yml
check-requirements.yml
#

- name: Fail if there is not enough space available in /
  fail:
    msg: |
      Not enough space available in /.
      Found {{ root_gb_available }} GB, required {{ bootstrap_host_data_disk_min_size }} GB)
  when:
    - bootstrap_host_data_disk_device == None
    - (host_root_space_available_bytes | int) < (host_data_disk_min_size_bytes | int)
  tags:
    - check-disk-size

# grep 50 tests/roles/bootstrap-host/defaults/main.yml
bootstrap_host_data_disk_min_size: 50
#

# grep bootstrap_host_data_disk_min_size tests/roles/bootstrap-host/defaults/main.yml
bootstrap_host_data_disk_min_size: 10
#

[root@c71 openstack-ansible]# ip -4 -o a
1: lo    inet 127.0.0.1/8 scope host lo\       valid_lft forever preferred_lft forever
2: eth0    inet 10.0.2.15/24 brd 10.0.2.255 scope global noprefixroute dynamic eth0\       valid_lft 84515sec preferred_lft 84515sec
3: br-mgmt    inet 172.29.236.100/22 brd 172.29.239.255 scope global br-mgmt\       valid_lft forever preferred_lft forever
4: br-storage    inet 172.29.244.100/22 brd 172.29.247.255 scope global br-storage\       valid_lft forever preferred_lft forever
5: br-vlan    inet 172.29.248.100/22 brd 172.29.251.255 scope global br-vlan\       valid_lft forever preferred_lft forever
5: br-vlan    inet 172.29.248.1/22 brd 172.29.251.255 scope global secondary br-vlan:0\       valid_lft forever preferred_lft forever
8: br-vxlan    inet 172.29.240.100/22 brd 172.29.243.255 scope global br-vxlan\       valid_lft forever preferred_lft forever

# ls ifcfg-*
ifcfg-br-mgmt  ifcfg-br-storage  ifcfg-br-vlan  ifcfg-br-vlan:0  ifcfg-br-vxlan  ifcfg-eth0  ifcfg-lo
#

# head -1000 ifcfg-*
==> ifcfg-br-mgmt <==
DEVICE=br-mgmt
TYPE=Bridge
IPADDR=172.29.236.100
NETMASK=255.255.252.0
ONBOOT=yes
BOOTPROTO=none
NM_CONTROLLED=no
DELAY=0
ETHTOOL_OPTS="-K ${DEVICE} sg off"

==> ifcfg-br-storage <==
DEVICE=br-storage
TYPE=Bridge
IPADDR=172.29.244.100
NETMASK=255.255.252.0
ONBOOT=yes
BOOTPROTO=none
NM_CONTROLLED=no
DELAY=0
ETHTOOL_OPTS="-K ${DEVICE} sg off"

==> ifcfg-br-vlan <==
# This interface has a veth peer
DEVICE=br-vlan
TYPE=Bridge
IPADDR=172.29.248.100
NETMASK=255.255.252.0
ONBOOT=yes
BOOTPROTO=none
NM_CONTROLLED=no
DELAY=0
ETHTOOL_OPTS="-K ${DEVICE} sg off"

==> ifcfg-br-vlan:0 <==
# This interface is an alias
DEVICE=br-vlan:0
IPADDR=172.29.248.1
NETMASK=255.255.252.0
ONBOOT=yes

==> ifcfg-br-vxlan <==
DEVICE=br-vxlan
TYPE=Bridge
IPADDR=172.29.240.100
NETMASK=255.255.252.0
ONBOOT=yes
BOOTPROTO=none
NM_CONTROLLED=no
DELAY=0
ETHTOOL_OPTS="-K ${DEVICE} sg off"

==> ifcfg-eth0 <==
DEVICE="eth0"
BOOTPROTO="dhcp"
ONBOOT="yes"
TYPE="Ethernet"
PERSISTENT_DHCLIENT="yes"

==> ifcfg-lo <==
DEVICE=lo
IPADDR=127.0.0.1
NETMASK=255.0.0.0
NETWORK=127.0.0.0
# If you're having problems with gated making 127.0.0.0/8 a martian,
# you can change this to something else (255.255.255.255, for example)
BROADCAST=127.255.255.255
ONBOOT=yes
NAME=loopback
#

# brctl show
bridge name	bridge id		STP enabled	interfaces
br-mgmt		8000.000000000000	no
br-storage		8000.000000000000	no
br-vlan		8000.c22fbc05933f	no		br-vlan-veth
br-vxlan		8000.000000000000	no
#


# ip a
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
    inet6 ::1/128 scope host
       valid_lft forever preferred_lft forever
2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000
    link/ether 52:54:00:8a:fe:e6 brd ff:ff:ff:ff:ff:ff
    inet 10.0.2.15/24 brd 10.0.2.255 scope global noprefixroute dynamic eth0
       valid_lft 84157sec preferred_lft 84157sec
    inet6 fe80::5054:ff:fe8a:fee6/64 scope link
       valid_lft forever preferred_lft forever
3: br-mgmt: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UNKNOWN group default qlen 1000
    link/ether 36:da:e5:74:27:43 brd ff:ff:ff:ff:ff:ff
    inet 172.29.236.100/22 brd 172.29.239.255 scope global br-mgmt
       valid_lft forever preferred_lft forever
    inet6 fe80::34da:e5ff:fe74:2743/64 scope link
       valid_lft forever preferred_lft forever
4: br-storage: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UNKNOWN group default qlen 1000
    link/ether 2a:3f:84:ad:8e:ca brd ff:ff:ff:ff:ff:ff
    inet 172.29.244.100/22 brd 172.29.247.255 scope global br-storage
       valid_lft forever preferred_lft forever
    inet6 fe80::283f:84ff:fead:8eca/64 scope link
       valid_lft forever preferred_lft forever
5: br-vlan: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP group default qlen 1000
    link/ether c2:2f:bc:05:93:3f brd ff:ff:ff:ff:ff:ff
    inet 172.29.248.100/22 brd 172.29.251.255 scope global br-vlan
       valid_lft forever preferred_lft forever
    inet 172.29.248.1/22 brd 172.29.251.255 scope global secondary br-vlan:0
       valid_lft forever preferred_lft forever
    inet6 fe80::eccd:2aff:fe3f:668/64 scope link
       valid_lft forever preferred_lft forever
6: eth12@br-vlan-veth: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP group default qlen 1000
    link/ether 12:4c:ad:0b:08:a3 brd ff:ff:ff:ff:ff:ff
    inet6 fe80::104c:adff:fe0b:8a3/64 scope link
       valid_lft forever preferred_lft forever
7: br-vlan-veth@eth12: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue master br-vlan state UP group default qlen 1000
    link/ether c2:2f:bc:05:93:3f brd ff:ff:ff:ff:ff:ff
    inet6 fe80::c02f:bcff:fe05:933f/64 scope link
       valid_lft forever preferred_lft forever
8: br-vxlan: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UNKNOWN group default qlen 1000
    link/ether 32:74:c4:49:b1:96 brd ff:ff:ff:ff:ff:ff
    inet 172.29.240.100/22 brd 172.29.243.255 scope global br-vxlan
       valid_lft forever preferred_lft forever
    inet6 fe80::3074:c4ff:fe49:b196/64 scope link
       valid_lft forever preferred_lft forever
#

# ovs-vsctl
-bash: ovs-vsctl: command not found
#

# bridge link
7: br-vlan-veth state UP @eth12: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 master br-vlan state forwarding priority 32 cost 2
#

# ip a | grep veth
6: eth12@br-vlan-veth: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP group default qlen 1000
7: br-vlan-veth@eth12: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue master br-vlan state UP group default qlen 1000
#

# ip a s eth12
6: eth12@br-vlan-veth: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP group default qlen 1000
    link/ether 12:4c:ad:0b:08:a3 brd ff:ff:ff:ff:ff:ff
    inet6 fe80::104c:adff:fe0b:8a3/64 scope link
       valid_lft forever preferred_lft forever
#

# pwd
/opt/openstack-ansible/playbooks
#

# pwd
/etc/openstack_deploy
# ls openstack_user_config.yml user_variables.yml
openstack_user_config.yml  user_variables.yml
#

# pstree
systemd─┬─NetworkManager─┬─dhclient
        │                └─2*[{NetworkManager}]
        ├─agetty
        ├─anacron
        ├─auditd───{auditd}
        ├─chronyd
        ├─crond
        ├─dbus-daemon───{dbus-daemon}
        ├─dnsmasq
        ├─gssproxy───5*[{gssproxy}]
        ├─lvmetad
        ├─master─┬─pickup
        │        └─qmgr
        ├─polkitd───6*[{polkitd}]
        ├─rpcbind
        ├─rsyslogd───2*[{rsyslogd}]
        ├─ssh
        ├─sshd───sshd───bash───sudo───bash───bash───ansible-playboo─┬─ansible-playboo───ssh
        │                                                           └─2*[{ansible-playboo}]
        ├─sshd───sh───python───python───gtar───xz
        ├─sshd───sshd───bash───sudo───bash───pstree
        ├─sshd
        ├─systemd-journal
        ├─systemd-logind
        ├─systemd-machine
        ├─systemd-udevd
        └─tuned───4*[{tuned}]
#

TASK [lxc_hosts : Ensure that the LXC cache has been prepared] *********************************************************************************************************************************************
Thursday 18 July 2019  13:18:01 +0000 (0:00:00.786)       0:11:04.241 *********
FAILED - RETRYING: Ensure that the LXC cache has been prepared (120 retries left).
FAILED - RETRYING: Ensure that the LXC cache has been prepared (119 retries left).
FAILED - RETRYING: Ensure that the LXC cache has been prepared (118 retries left).
changed: [aio1]

ASK [lxc_container_create : Create container (dir)]

# lxc-ls --fancy
NAME                                   STATE   AUTOSTART GROUPS            IPV4 IPV6
aio1_horizon_container-cb145a57        STOPPED 1         onboot, openstack -    -
aio1_keystone_container-1753b49d       STOPPED 1         onboot, openstack -    -
aio1_neutron_server_container-75989006 STOPPED 1         onboot, openstack -    -
aio1_swift_proxy_container-6f69669c    STOPPED 1         onboot, openstack -    -
aio1_utility_container-8d3db5a0        STOPPED 1         onboot, openstack -    -
#

# lxc-info --name aio1_horizon_container-cb145a57
Name:           aio1_horizon_container-cb145a57
State:          RUNNING
PID:            22361
CPU use:        0.75 seconds
BlkIO use:      72.71 MiB
Memory use:     8.99 MiB
KMem use:       0 bytes
Link:           vethN938XE
 TX bytes:      656 bytes
 RX bytes:      3.20 KiB
 Total bytes:   3.84 KiB
#

# lxc-ls --fancy
NAME                                   STATE   AUTOSTART GROUPS            IPV4 IPV6
aio1_cinder_api_container-ade654c3     STOPPED 1         onboot, openstack -    -
aio1_designate_container-1a360417      STOPPED 1         onboot, openstack -    -
aio1_glance_container-03078ce1         STOPPED 1         onboot, openstack -    -
aio1_horizon_container-cb145a57        RUNNING 1         onboot, openstack -    -
aio1_keystone_container-1753b49d       RUNNING 1         onboot, openstack -    -
aio1_memcached_container-4cb65778      STOPPED 1         onboot, openstack -    -
aio1_neutron_server_container-75989006 RUNNING 1         onboot, openstack -    -
aio1_repo_container-e846b452           STOPPED 1         onboot, openstack -    -
aio1_swift_proxy_container-6f69669c    RUNNING 1         onboot, openstack -    -
aio1_utility_container-8d3db5a0        RUNNING 1         onboot, openstack -    -
#

 free -m
              total        used        free      shared  buff/cache   available
Mem:            487         289           5          20         192         122
Swap:

# df -h
Filesystem      Size  Used Avail Use% Mounted on
/dev/sda1        40G   11G   30G  27% /
devtmpfs        237M     0  237M   0% /dev
tmpfs           244M  324K  244M   1% /dev/shm
tmpfs           244M  680K  243M   1% /run
tmpfs           244M     0  244M   0% /sys/fs/cgroup
tmpfs            49M     0   49M   0% /run/user/1000
/dev/loop0      128G  465M  126G   1% /var/lib/machines
/dev/loop2     1008G   77M  957G   1% /var/lib/nova/instances
/dev/loop3      1.0T   33M  1.0T   1% /srv/swift1.img
/dev/loop4      1.0T   33M  1.0T   1% /srv/swift2.img
/dev/loop5      1.0T   33M  1.0T   1% /srv/swift3.img
tmpfs            49M     0   49M   0% /run/user/0
#

? df -h
Filesystem      Size   Used  Avail Capacity iused               ifree %iused  Mounted on
/dev/disk1s1    70Gi   65Gi  2.0Gi    98%  868105 9223372036853907702    0%   /
devfs          191Ki  191Ki    0Bi   100%     662                   0  100%   /dev
/dev/disk1s4    70Gi  2.0Gi  2.0Gi    51%       2 9223372036854775805    0%   /private/var/vm
/dev/disk0s3   9.2Gi  206Mi  9.0Gi     3%    6576              296048    2%   /Volumes/SHARE
map -hosts       0Bi    0Bi    0Bi   100%       0                   0  100%   /net
map auto_home    0Bi    0Bi    0Bi   100%       0                   0  100%   /home
/dev/disk0s4    33Gi   27Gi  6.5Gi    81%  273912             6925788    4%   /Volumes/BOOTCAMP
?

? df -Pk
Filesystem    1024-blocks     Used Available Capacity  Mounted on
/dev/disk1s1     73204200 61325516   8594084    88%    /
devfs                 191      191         0   100%    /dev
/dev/disk1s4     73204200  2097504   8594084    20%    /private/var/vm
/dev/disk0s3      9683968   210432   9473536     3%    /Volumes/SHARE
map -hosts              0        0         0   100%    /net
map auto_home           0        0         0   100%    /home
/dev/disk0s4     34756240 27915708   6840532    81%    /Volumes/BOOTCAMP
?

# free -m
              total        used        free      shared  buff/cache   available
Mem:            487         260          24          22         201         143
Swap:          2047         361        1686
#

# lxc-ls --fancy
NAME                                   STATE   AUTOSTART GROUPS            IPV4 IPV6
aio1_cinder_api_container-ade654c3     RUNNING 1         onboot, openstack -    -
aio1_designate_container-1a360417      RUNNING 1         onboot, openstack -    -
aio1_galera_container-fd677ef1         RUNNING 1         onboot, openstack -    -
aio1_glance_container-03078ce1         RUNNING 1         onboot, openstack -    -
aio1_heat_api_container-db22c2e3       RUNNING 1         onboot, openstack -    -
aio1_horizon_container-cb145a57        RUNNING 1         onboot, openstack -    -
aio1_keystone_container-1753b49d       RUNNING 1         onboot, openstack -    -
aio1_memcached_container-4cb65778      RUNNING 1         onboot, openstack -    -
aio1_neutron_server_container-75989006 RUNNING 1         onboot, openstack -    -
aio1_nova_api_container-9045adf7       RUNNING 1         onboot, openstack -    -
aio1_rabbit_mq_container-1247be91      RUNNING 1         onboot, openstack -    -
aio1_repo_container-e846b452           RUNNING 1         onboot, openstack -    -
aio1_rsyslog_container-2845845e        RUNNING 1         onboot, openstack -    -
aio1_swift_proxy_container-6f69669c    RUNNING 1         onboot, openstack -    -
aio1_utility_container-8d3db5a0        RUNNING 1         onboot, openstack -    -
#

# bridge link
7: br-vlan-veth state UP @eth12: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 master br-vlan state forwarding priority 32 cost 2
11: vethIAS75F state UP @(null): <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 master lxcbr0 state forwarding priority 32 cost 2
13: vethN938XE state UP @(null): <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 master lxcbr0 state forwarding priority 32 cost 2
15: vethSLM8F1 state UP @(null): <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 master lxcbr0 state forwarding priority 32 cost 2
17: vethYFA2WQ state UP @(null): <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 master lxcbr0 state forwarding priority 32 cost 2
19: vethHA8ANX state UP @(null): <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 master lxcbr0 state forwarding priority 32 cost 2
21: vethDVORXC state UP @(null): <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 master lxcbr0 state forwarding priority 32 cost 2
23: vethJGJ1MS state UP @(null): <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 master lxcbr0 state forwarding priority 32 cost 2
25: veth36F943 state UP @(null): <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 master lxcbr0 state forwarding priority 32 cost 2
27: veth21PQ2R state UP @(null): <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 master lxcbr0 state forwarding priority 32 cost 2
29: vethG3QL94 state UP @(null): <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 master lxcbr0 state forwarding priority 32 cost 2
31: veth74OGXW state UP @(null): <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 master lxcbr0 state forwarding priority 32 cost 2
33: veth53KP4T state UP @(null): <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 master lxcbr0 state forwarding priority 32 cost 2
35: vethAPIEYQ state UP @(null): <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 master lxcbr0 state forwarding priority 32 cost 2
37: veth6BY9AS state UP @(null): <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 master lxcbr0 state forwarding priority 32 cost 2
39: vethU02YU6 state UP @(null): <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 master lxcbr0 state forwarding priority 32 cost 2

# brctl show
bridge name	bridge id		STP enabled	interfaces
br-mgmt		8000.000000000000	no
br-storage		8000.000000000000	no
br-vlan		8000.c22fbc05933f	no		br-vlan-veth
br-vxlan		8000.000000000000	no
lxcbr0		8000.fe030a91e2b0	no		veth21PQ2R
							veth36F943
							veth53KP4T
							veth6BY9AS
							veth74OGXW
							vethAPIEYQ
							vethDVORXC
							vethG3QL94
							vethHA8ANX
							vethIAS75F
							vethJGJ1MS
							vethN938XE
							vethSLM8F1
							vethU02YU6
							vethYFA2WQ
#

TASK [lxc_container_create : Add veth pair name to match container name]

TASK [lxc_container_create : Run container veth wiring script]





# lxc-ls --fancy
NAME                                   STATE   AUTOSTART GROUPS            IPV4           IPV6
aio1_cinder_api_container-ade654c3     RUNNING 1         onboot, openstack -              -
aio1_designate_container-1a360417      RUNNING 1         onboot, openstack -              -
aio1_galera_container-fd677ef1         RUNNING 1         onboot, openstack -              -
aio1_glance_container-03078ce1         RUNNING 1         onboot, openstack -              -
aio1_heat_api_container-db22c2e3       RUNNING 1         onboot, openstack -              -
aio1_horizon_container-cb145a57        RUNNING 1         onboot, openstack 172.29.236.87  -
aio1_keystone_container-1753b49d       RUNNING 1         onboot, openstack 172.29.237.126 -
aio1_memcached_container-4cb65778      RUNNING 1         onboot, openstack -              -
aio1_neutron_server_container-75989006 RUNNING 1         onboot, openstack -              -
aio1_nova_api_container-9045adf7       RUNNING 1         onboot, openstack -              -
aio1_rabbit_mq_container-1247be91      RUNNING 1         onboot, openstack -              -
aio1_repo_container-e846b452           RUNNING 1         onboot, openstack -              -
aio1_rsyslog_container-2845845e        RUNNING 1         onboot, openstack -              -
aio1_swift_proxy_container-6f69669c    RUNNING 1         onboot, openstack 172.29.238.119 -
aio1_utility_container-8d3db5a0        RUNNING 1         onboot, openstack 172.29.239.191 -
#


# lxc-ls --fancy
NAME                                   STATE   AUTOSTART GROUPS            IPV4                           IPV6
aio1_cinder_api_container-ade654c3     RUNNING 1         onboot, openstack 172.29.236.153, 172.29.244.182 -
aio1_designate_container-1a360417      RUNNING 1         onboot, openstack 172.29.238.217                 -
aio1_galera_container-fd677ef1         RUNNING 1         onboot, openstack 172.29.239.221                 -
aio1_glance_container-03078ce1         RUNNING 1         onboot, openstack 172.29.237.247, 172.29.245.112 -
aio1_heat_api_container-db22c2e3       RUNNING 1         onboot, openstack 172.29.238.75                  -
aio1_horizon_container-cb145a57        RUNNING 1         onboot, openstack 172.29.236.87                  -
aio1_keystone_container-1753b49d       RUNNING 1         onboot, openstack 172.29.237.126                 -
aio1_memcached_container-4cb65778      RUNNING 1         onboot, openstack 172.29.239.117                 -
aio1_neutron_server_container-75989006 RUNNING 1         onboot, openstack 172.29.238.16                  -
aio1_nova_api_container-9045adf7       RUNNING 1         onboot, openstack 172.29.237.23                  -
aio1_rabbit_mq_container-1247be91      RUNNING 1         onboot, openstack 172.29.238.162                 -
aio1_repo_container-e846b452           RUNNING 1         onboot, openstack 172.29.236.76                  -
aio1_rsyslog_container-2845845e        RUNNING 1         onboot, openstack 172.29.236.64                  -
aio1_swift_proxy_container-6f69669c    RUNNING 1         onboot, openstack 172.29.238.119, 172.29.245.33  -
aio1_utility_container-8d3db5a0        RUNNING 1         onboot, openstack 172.29.239.191                 -
#

# lxc-info --name aio1_horizon_container-cb145a57
Name:           aio1_horizon_container-cb145a57
State:          RUNNING
PID:            22361
IP:             172.29.236.87
CPU use:        6.92 seconds
BlkIO use:      713.13 MiB
Memory use:     1.96 MiB
KMem use:       0 bytes
Link:           vethN938XE
 TX bytes:      656 bytes
 RX bytes:      9.61 KiB
 Total bytes:   10.25 KiB
#


# top -n 1

top - 13:41:28 up  1:19,  2 users,  load average: 36.88, 16.26, 9.33
Tasks: 362 total,  41 running, 316 sleeping,   0 stopped,   5 zombie
%Cpu(s):  6.2 us, 46.2 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi, 47.7 si,  0.0 st
KiB Mem :   498888 total,     6360 free,   279208 used,   213320 buff/cache
KiB Swap:  2097148 total,  1752060 free,   345088 used.    93948 avail Mem

  PID USER      PR  NI    VIRT    RES    SHR S %CPU %MEM     TIME+ COMMAND
  33 root      20   0       0      0      0 R 12.7  0.0   0:36.13 kswapd0

TASK [lxc_container_create : Wait for container connectivity]

# ip -4 -o a
1: lo    inet 127.0.0.1/8 scope host lo\       valid_lft forever preferred_lft forever
2: eth0    inet 10.0.2.15/24 brd 10.0.2.255 scope global noprefixroute dynamic eth0\       valid_lft 81556sec preferred_lft 81556sec
3: br-mgmt    inet 172.29.236.100/22 brd 172.29.239.255 scope global br-mgmt\       valid_lft forever preferred_lft forever
4: br-storage    inet 172.29.244.100/22 brd 172.29.247.255 scope global br-storage\       valid_lft forever preferred_lft forever
5: br-vlan    inet 172.29.248.100/22 brd 172.29.251.255 scope global br-vlan\       valid_lft forever preferred_lft forever
5: br-vlan    inet 172.29.248.1/22 brd 172.29.251.255 scope global secondary br-vlan:0\       valid_lft forever preferred_lft forever
8: br-vxlan    inet 172.29.240.100/22 brd 172.29.243.255 scope global br-vxlan\       valid_lft forever preferred_lft forever
9: lxcbr0    inet 10.255.255.1/24 brd 10.255.255.255 scope global noprefixroute lxcbr0\       valid_lft forever preferred_lft forever
#

# brctl show
bridge name	bridge id		STP enabled	interfaces
br-mgmt		8000.fe188daeb570	no		03078ce1_eth1
							1247be91_eth1
							1753b49d_eth1
							1a360417_eth1
							2845845e_eth1
							4cb65778_eth1
							6f69669c_eth1
							75989006_eth1
							8d3db5a0_eth1
							9045adf7_eth1
							ade654c3_eth1
							cb145a57_eth1
							db22c2e3_eth1
							e846b452_eth1
							fd677ef1_eth1
br-storage		8000.fe17a5e00672	no		03078ce1_eth2
							6f69669c_eth2
							ade654c3_eth2
br-vlan		8000.c22fbc05933f	no		br-vlan-veth
br-vxlan		8000.000000000000	no
lxcbr0		8000.fe05dbf1432f	no		03078ce1_eth0
							1247be91_eth0
							1753b49d_eth0
							1a360417_eth0
							2845845e_eth0
							4cb65778_eth0
							6f69669c_eth0
							75989006_eth0
							8d3db5a0_eth0
							9045adf7_eth0
							ade654c3_eth0
							cb145a57_eth0
							db22c2e3_eth0
							e846b452_eth0
							fd677ef1_eth0
#


# lxc-ls --fancy
NAME                                   STATE   AUTOSTART GROUPS            IPV4           IPV6
aio1_cinder_api_container-ade654c3     RUNNING 1         onboot, openstack 10.255.255.233 -
aio1_designate_container-1a360417      RUNNING 1         onboot, openstack 10.255.255.230 -
aio1_galera_container-fd677ef1         RUNNING 1         onboot, openstack 10.255.255.204 -
aio1_glance_container-03078ce1         RUNNING 1         onboot, openstack 10.255.255.34  -
aio1_heat_api_container-db22c2e3       RUNNING 1         onboot, openstack 10.255.255.131 -
aio1_horizon_container-cb145a57        RUNNING 1         onboot, openstack 10.255.255.158 -
aio1_keystone_container-1753b49d       RUNNING 1         onboot, openstack 10.255.255.248 -
aio1_memcached_container-4cb65778      RUNNING 1         onboot, openstack 10.255.255.225 -
aio1_neutron_server_container-75989006 RUNNING 1         onboot, openstack 10.255.255.180 -
aio1_nova_api_container-9045adf7       RUNNING 1         onboot, openstack 10.255.255.43  -
aio1_rabbit_mq_container-1247be91      RUNNING 1         onboot, openstack 10.255.255.160 -
aio1_repo_container-e846b452           RUNNING 1         onboot, openstack 10.255.255.184 -
aio1_rsyslog_container-2845845e        RUNNING 1         onboot, openstack 10.255.255.133 -
aio1_swift_proxy_container-6f69669c    RUNNING 1         onboot, openstack 10.255.255.111 -
aio1_utility_container-8d3db5a0        RUNNING 1         onboot, openstack 10.255.255.93  -
#

# cat /etc/hosts
127.0.0.1 localhost aio1
127.0.1.1 aio1.openstack.local aio1

# The following lines are desirable for IPv6 capable hosts
::1 ip6-localhost ip6-loopback
fe00::0 ip6-localnet
ff00::0 ip6-mcastprefix
ff02::1 ip6-allnodes
ff02::2 ip6-allrouters
ff02::3 ip6-allhosts
172.29.236.100 aio1.openstack.local aio1
172.29.239.191 aio1-utility-container-8d3db5a0.openstack.local aio1-utility-container-8d3db5a0 aio1_utility_container-8d3db5a0
172.29.238.119 aio1-swift-proxy-container-6f69669c.openstack.local aio1-swift-proxy-container-6f69669c aio1_swift_proxy_container-6f69669c
172.29.237.247 aio1-glance-container-03078ce1.openstack.local aio1-glance-container-03078ce1 aio1_glance_container-03078ce1
172.29.238.16 aio1-neutron-server-container-75989006.openstack.local aio1-neutron-server-container-75989006 aio1_neutron_server_container-75989006
172.29.236.76 aio1-repo-container-e846b452.openstack.local aio1-repo-container-e846b452 aio1_repo_container-e846b452
172.29.239.117 aio1-memcached-container-4cb65778.openstack.local aio1-memcached-container-4cb65778 aio1_memcached_container-4cb65778
172.29.239.221 aio1-galera-container-fd677ef1.openstack.local aio1-galera-container-fd677ef1 aio1_galera_container-fd677ef1
172.29.238.162 aio1-rabbit-mq-container-1247be91.openstack.local aio1-rabbit-mq-container-1247be91 aio1_rabbit_mq_container-1247be91
172.29.238.217 aio1-designate-container-1a360417.openstack.local aio1-designate-container-1a360417 aio1_designate_container-1a360417
172.29.236.153 aio1-cinder-api-container-ade654c3.openstack.local aio1-cinder-api-container-ade654c3 aio1_cinder_api_container-ade654c3
172.29.236.87 aio1-horizon-container-cb145a57.openstack.local aio1-horizon-container-cb145a57 aio1_horizon_container-cb145a57
172.29.237.126 aio1-keystone-container-1753b49d.openstack.local aio1-keystone-container-1753b49d aio1_keystone_container-1753b49d
172.29.238.75 aio1-heat-api-container-db22c2e3.openstack.local aio1-heat-api-container-db22c2e3 aio1_heat_api_container-db22c2e3
172.29.237.23 aio1-nova-api-container-9045adf7.openstack.local aio1-nova-api-container-9045adf7 aio1_nova_api_container-9045adf7
172.29.236.64 aio1-rsyslog-container-2845845e.openstack.local aio1-rsyslog-container-2845845e aio1_rsyslog_container-2845845e
#

TASK [openstack_hosts : If a keyfile is provided, copy the gpg keyfile to the key location]

# pstree
systemd─┬─NetworkManager─┬─dhclient
        │                └─2*[{NetworkManager}]
        ├─agetty
        ├─auditd───{auditd}
        ├─chronyd
        ├─crond
        ├─dbus-daemon───{dbus-daemon}
        ├─dnsmasq
        ├─gssproxy───5*[{gssproxy}]
        ├─lvmetad
        ├─15*[lxc-start───systemd─┬─5*[agetty]]
        │                         ├─crond]
        │                         ├─dbus-daemon]
        │                         ├─dhclient]
        │                         ├─rsyslogd───2*[{rsyslogd}]]
        │                         ├─sshd]
        │                         ├─systemd-journal]
        │                         └─systemd-logind]
        ├─master─┬─pickup
        │        └─qmgr
        ├─polkitd───6*[{polkitd}]
        ├─rpcbind
        ├─rsyslogd───5*[{rsyslogd}]
        ├─ssh
        ├─sshd───sshd───bash───sudo───bash───bash───ansible-playboo─┬─5*[ansible-playboo───ssh]
        │                                                           └─2*[{ansible-playboo}]
        ├─sshd───sshd───bash───sudo───bash───pstree
        ├─sshd───sshd───5*[lxc-attach───su───sh───python───python───yum]
        ├─systemd-journal
        ├─systemd-logind
        ├─systemd-udevd
        └─tuned───4*[{tuned}]
#

TASK [openstack_hosts : Add requirement packages (repositories gpg keys packages, toolkits...)]

# free -m
              total        used        free      shared  buff/cache   available
Mem:            487         371           6           0         109          45
Swap:          2047        1442         605
#


[ERROR]: User interrupted execution

# openstack-ansible setup-hosts.yml

so again?!
* part 2 on virtualbox with many interfaces

"vm_deployer_1563794608410_18016" 
"vm_control_1563795073812_19332"
"vm_compute_1563795546380_95137"
"vm_storage_1563796007834_66559"

vboxmanage modifyvm "vm_deployer_1563794608410_18016" --hostonlyadapter4 "VirtualBox Host-Only Ethernet Adapter #3"
vboxmanage modifyvm "vm_deployer_1563794608410_18016" --nic4 hostonly
vboxmanage modifyvm "vm_deployer_1563794608410_18016" --hostonlyadapter5 "VirtualBox Host-Only Ethernet Adapter #4"
vboxmanage modifyvm "vm_deployer_1563794608410_18016" --nic5 hostonly
vboxmanage modifyvm "vm_deployer_1563794608410_18016" --hostonlyadapter6 "VirtualBox Host-Only Ethernet Adapter #5"
vboxmanage modifyvm "vm_deployer_1563794608410_18016" --nic6 hostonly

vboxmanage modifyvm "vm_control_1563795073812_19332" --hostonlyadapter4 "VirtualBox Host-Only Ethernet Adapter #3"
vboxmanage modifyvm "vm_control_1563795073812_19332" --nic4 hostonly
vboxmanage modifyvm "vm_control_1563795073812_19332" --hostonlyadapter5 "VirtualBox Host-Only Ethernet Adapter #4"
vboxmanage modifyvm "vm_control_1563795073812_19332" --nic5 hostonly
vboxmanage modifyvm "vm_control_1563795073812_19332" --hostonlyadapter6 "VirtualBox Host-Only Ethernet Adapter #5"
vboxmanage modifyvm "vm_control_1563795073812_19332" --nic6 hostonly

vboxmanage modifyvm "vm_compute_1563795546380_95137" --hostonlyadapter4 "VirtualBox Host-Only Ethernet Adapter #3"
vboxmanage modifyvm "vm_compute_1563795546380_95137" --nic4 hostonly
vboxmanage modifyvm "vm_compute_1563795546380_95137" --hostonlyadapter5 "VirtualBox Host-Only Ethernet Adapter #4"
vboxmanage modifyvm "vm_compute_1563795546380_95137" --nic5 hostonly
vboxmanage modifyvm "vm_compute_1563795546380_95137" --hostonlyadapter6 "VirtualBox Host-Only Ethernet Adapter #5"
vboxmanage modifyvm "vm_compute_1563795546380_95137" --nic6 hostonly

vboxmanage modifyvm "vm_storage_1563796007834_66559" --hostonlyadapter4 "VirtualBox Host-Only Ethernet Adapter #3"
vboxmanage modifyvm "vm_storage_1563796007834_66559" --nic4 hostonly
vboxmanage modifyvm "vm_storage_1563796007834_66559" --hostonlyadapter5 "VirtualBox Host-Only Ethernet Adapter #4"
vboxmanage modifyvm "vm_storage_1563796007834_66559" --nic5 hostonly
vboxmanage modifyvm "vm_storage_1563796007834_66559" --hostonlyadapter6 "VirtualBox Host-Only Ethernet Adapter #5"
vboxmanage modifyvm "vm_storage_1563796007834_66559" --nic6 hostonly

vboxmanage showvminfo "vm_deployer_1563794608410_18016"  | more

yum install python-ethtool net-tools bridge-utils -y

* part 2 and fail to conn
  
** opendev.org connection fail

http://git.openstack.org/cgit/openstack/requirements/plain/upper-constraints.txt?id=6a92e89c14e68c42a149b719d93742979d241c5b
[2019-07-25 목 17:37] 오랜 실패의 시간을 소진하고 이제 된다. 이거참
아토에서 했으면 잘 됬을까?

열심히 그리고 opendev.org에서 파일을 받아온다.
- [ ] 오프라인으로 처리할 필요가 있다.

** bootstrap-aio.sh but syntax fail but right one as I can see

export PATH=/usr/local/bin:$PATH

then work! my

grep 50 tests/roles/bootstrap-host/defaults/main.yml
bootstrap_host_data_disk_min_size: 30

sed -i 's/50/30/' tests/roles/bootstrap-host/defaults/main.yml

* openstack-ansible setup-hosts.yml , hold again

TASK [ansible-hardening : Add or remove packages based on STIG requirements]
Friday 26 July 2019  11:43:58 +0900 (0:00:00.703)       0:06:00.246 
ok: [compute1] => (item=absent)
ok: [infra1] => (item=absent)
ok: [storage1] => (item=absent)

Ctrl-C

[root@control my]# rpm -qa
error: rpmdb: BDB0113 Thread/process 4426/140274796144704 failed: BDB1507 Thread died in Berkeley DB library
error: db5 error(-30973) from dbenv->failchk: BDB0087 DB_RUNRECOVERY: Fatal error, run database recovery
error: cannot open Packages index using db5 -  (-30973)
error: cannot open Packages database in /var/lib/rpm
error: rpmdb: BDB0113 Thread/process 4426/140274796144704 failed: BDB1507 Thread died in Berkeley DB library
error: db5 error(-30973) from dbenv->failchk: BDB0087 DB_RUNRECOVERY: Fatal error, run database recovery
error: cannot open Packages database in /var/lib/rpm
[root@control my]# 

rm -f /var/lib/rpm/__db*
rpm --rebuilddb

on control and storage, wait long have to wait long enough

/opt/openstack-ansible/playbooks/ 
setup-hosts.yml
setup-infrastructure.hml

/etc/openstack-deploy/ 
openstack_user_config.yml 
user_variables.yml

ansible-hardening

TASK [lxc_container_create : Create container (dir)] ***********************************************************************************************************
Friday 26 July 2019  13:43:30 +0900 (0:00:01.893)       0:12:04.867 *********** 
fatal: [infra1_keystone_container-af9f1617 -> 172.29.236.11]: FAILED! => {"changed": false, "failed": true, "msg": "The `lxc` module is not importable. Check the requirements."}
fatal: [infra1_neutron_server_container-1dbe0b7a -> 172.29.236.11]: FAILED! => {"changed": false, "failed": true, "msg": "The `lxc` module is not importable. Check the requirements."}
fatal: [infra1_utility_container-0674895c -> 172.29.236.11]: FAILED! => {"changed": false, "failed": true, "msg": "The `lxc` module is not importable. Check the requirements."}
fatal: [infra1_horizon_container-fbd3b559 -> 172.29.236.11]: FAILED! => {"changed": false, "failed": true, "msg": "The `lxc` module is not importable. Check the requirements."}
fatal: [infra1_repo_container-1de92927 -> 172.29.236.11]: FAILED! => {"changed": false, "failed": true, "msg": "The `lxc` module is not importable. Check the requirements."}
fatal: [infra1_glance_container-ed0fcd59 -> 172.29.236.11]: FAILED! => {"changed": false, "failed": true, "msg": "The `lxc` module is not importable. Check the requirements."}
fatal: [infra1_memcached_container-7d277f71 -> 172.29.236.11]: FAILED! => {"changed": false, "failed": true, "msg": "The `lxc` module is not importable. Check the requirements."}
fatal: [infra1_cinder_api_container-6d9d4294 -> 172.29.236.11]: FAILED! => {"changed": false, "failed": true, "msg": "The `lxc` module is not importable. Check the requirements."}
fatal: [infra1_heat_api_container-3ca87b11 -> 172.29.236.11]: FAILED! => {"changed": false, "failed": true, "msg": "The `lxc` module is not importable. Check the requirements."}
fatal: [infra1_galera_container-11734601 -> 172.29.236.11]: FAILED! => {"changed": false, "failed": true, "msg": "The `lxc` module is not importable. Check the requirements."}
fatal: [infra1_nova_api_container-f34593d8 -> 172.29.236.11]: FAILED! => {"changed": false, "failed": true, "msg": "The `lxc` module is not importable. Check the requirements."}
fatal: [infra1_rabbit_mq_container-c34abfbe -> 172.29.236.11]: FAILED! => {"changed": false, "failed": true, "msg": "The `lxc` module is not importable. Check the requirements."}

PLAY RECAP *****************************************************************************************************************************************************
aio1                       : ok=0    changed=0    unreachable=1    failed=0   
aio1_cinder_api_container-c5058329 : ok=0    changed=0    unreachable=1    failed=0   
aio1_designate_container-0adb3958 : ok=0    changed=0    unreachable=1    failed=0   
aio1_galera_container-ffeb3190 : ok=0    changed=0    unreachable=1    failed=0   
aio1_glance_container-95d47c66 : ok=0    changed=0    unreachable=1    failed=0   
aio1_heat_api_container-0d531822 : ok=0    changed=0    unreachable=1    failed=0   
aio1_horizon_container-5d922e17 : ok=0    changed=0    unreachable=1    failed=0   
aio1_keystone_container-249da988 : ok=0    changed=0    unreachable=1    failed=0   
aio1_memcached_container-6405a10f : ok=0    changed=0    unreachable=1    failed=0   
aio1_neutron_server_container-5a9d0180 : ok=0    changed=0    unreachable=1    failed=0   
aio1_nova_api_container-a9c398e3 : ok=0    changed=0    unreachable=1    failed=0   
aio1_rabbit_mq_container-fcc2a0c8 : ok=0    changed=0    unreachable=1    failed=0   
aio1_repo_container-da809349 : ok=0    changed=0    unreachable=1    failed=0   
aio1_rsyslog_container-d3f65cc9 : ok=0    changed=0    unreachable=1    failed=0   
aio1_swift_proxy_container-ad4f8b12 : ok=0    changed=0    unreachable=1    failed=0   
aio1_utility_container-67d3edf4 : ok=0    changed=0    unreachable=1    failed=0   
compute1                   : ok=151  changed=25   unreachable=0    failed=0   
infra1                     : ok=54   changed=2    unreachable=0    failed=1   
infra1_cinder_api_container-6d9d4294 : ok=6    changed=2    unreachable=0    failed=1   
infra1_galera_container-11734601 : ok=6    changed=2    unreachable=0    failed=1   
infra1_glance_container-ed0fcd59 : ok=6    changed=2    unreachable=0    failed=1   
infra1_heat_api_container-3ca87b11 : ok=6    changed=2    unreachable=0    failed=1   
infra1_horizon_container-fbd3b559 : ok=6    changed=2    unreachable=0    failed=1   
infra1_keystone_container-af9f1617 : ok=6    changed=2    unreachable=0    failed=1   
infra1_memcached_container-7d277f71 : ok=6    changed=2    unreachable=0    failed=1   
infra1_neutron_server_container-1dbe0b7a : ok=6    changed=2    unreachable=0    failed=1   
infra1_nova_api_container-f34593d8 : ok=6    changed=2    unreachable=0    failed=1   
infra1_rabbit_mq_container-c34abfbe : ok=6    changed=2    unreachable=0    failed=1   
infra1_repo_container-1de92927 : ok=6    changed=2    unreachable=0    failed=1   
infra1_utility_container-0674895c : ok=6    changed=2    unreachable=0    failed=1   
storage1                   : ok=53   changed=2    unreachable=0    failed=1   

Friday 26 July 2019  13:43:36 +0900 (0:00:06.224)       0:12:11.093 *********** 
=============================================================================== 
ansible-hardening : Ensure RPM verification task has finished ----------------------------------------------------------------------------------------- 171.34s
lxc_container_create : Allow the usage of local facts ------------------------------------------------------------------------------------------------- 137.37s
Ensure python is installed ----------------------------------------------------------------------------------------------------------------------------- 44.40s
openstack_hosts : Drop hosts file entries script locally ----------------------------------------------------------------------------------------------- 28.73s
openstack_hosts : Adding new system tuning ------------------------------------------------------------------------------------------------------------- 20.41s
lxc_container_create : Container service directories --------------------------------------------------------------------------------------------------- 19.93s
ansible-hardening : Check each user to see if its home directory exists on the filesystem -------------------------------------------------------------- 17.86s
openstack_hosts : Load kernel module(s) ---------------------------------------------------------------------------------------------------------------- 17.38s
ansible-hardening : Add or remove packages based on STIG requirements ---------------------------------------------------------------------------------- 17.23s
pip_install : Install PIP ------------------------------------------------------------------------------------------------------------------------------ 15.56s
lxc_container_create : LXC autodev setup --------------------------------------------------------------------------------------------------------------- 11.08s
ansible-hardening : V-72269 - Synchronize system clock (configuration file) ----------------------------------------------------------------------------- 9.76s
lxc_container_create : Gather variables for each operating system --------------------------------------------------------------------------------------- 9.58s
lxc_container_create : Read custom facts from previous runs --------------------------------------------------------------------------------------------- 8.94s
ansible-hardening : Set sysctl configurations ----------------------------------------------------------------------------------------------------------- 7.16s
lxc_container_create : Create container (dir) ----------------------------------------------------------------------------------------------------------- 6.22s
openstack_hosts : Write list of modules to load at boot ------------------------------------------------------------------------------------------------- 4.88s
ansible-hardening : Adjust auditd/audispd configurations ------------------------------------------------------------------------------------------------ 3.75s
openstack_hosts : If a keyfile is provided, copy the gpg keyfile to the key location -------------------------------------------------------------------- 3.54s
ansible-hardening : Deploy rules for auditd based on STIG requirements ---------------------------------------------------------------------------------- 3.24s

EXIT NOTICE [Playbook execution failure] **************************************
===============================================================================


[root@storage ~]# rpm -qa
error: rpmdb: BDB0113 Thread/process 5878/139940613572672 failed: BDB1507 Thread died in Berkeley DB library
error: db5 error(-30973) from dbenv->failchk: BDB0087 DB_RUNRECOVERY: Fatal error, run database recovery
error: cannot open Packages index using db5 -  (-30973)
error: cannot open Packages database in /var/lib/rpm
error: rpmdb: BDB0113 Thread/process 5878/139940613572672 failed: BDB1507 Thread died in Berkeley DB library
error: db5 error(-30973) from dbenv->failchk: BDB0087 DB_RUNRECOVERY: Fatal error, run database recovery
error: cannot open Packages database in /var/lib/rpm
[root@storage ~]# rm -f /var/lib/rpm/__db.00*
[root@storage ~]# rpm --rebuilddb
[root@storage ~]# yum-complete-transaction 
Loaded plugins: fastestmirror, priorities, rpm-warm-cache
Loading mirror speeds from cached hostfile
 * base: mirror.navercorp.com
 * epel: mirror.horizon.vn
 * extras: mirror.navercorp.com
 * updates: mirror.navercorp.com
555 packages excluded due to repository priority protections
There are 1 outstanding transactions to complete. Finishing the most recent one
The remaining transaction had 5 elements left to run
Package aide-0.15.1-13.el7.x86_64 already installed and latest version
Package audispd-plugins-2.8.4-4.el7.x86_64 already installed and latest version
--> Running transaction check
---> Package dracut-fips.x86_64 0:033-554.el7 will be installed
---> Package dracut-fips-aesni.x86_64 0:033-554.el7 will be installed
---> Package hmaccalc.x86_64 0:0.9.13-4.el7 will be installed
--> Finished Dependency Resolution

Dependencies Resolved

==============================================================================================================================================================================================================================================================================
 Package                                                                  Arch                                                          Version                                                             Repository                                                   Size
==============================================================================================================================================================================================================================================================================
Installing:
 dracut-fips                                                              x86_64                                                        033-554.el7                                                         base                                                         61 k
 dracut-fips-aesni                                                        x86_64                                                        033-554.el7                                                         base                                                         65 k
 hmaccalc                                                                 x86_64                                                        0.9.13-4.el7                                                        base                                                         26 k

Transaction Summary
==============================================================================================================================================================================================================================================================================
Install  3 Packages

Total size: 152 k
Installed size: 125 k
Is this ok [y/d/N]: y
Downloading packages:
Running transaction check
Running transaction test
Transaction test succeeded
Running transaction
  Installing : hmaccalc-0.9.13-4.el7.x86_64                                                                                                                                                                                                                               1/3 
  Installing : dracut-fips-033-554.el7.x86_64                                                                                                                                                                                                                             2/3 
  Installing : dracut-fips-aesni-033-554.el7.x86_64                                                                                                                                                                                                                       3/3 
  Verifying  : hmaccalc-0.9.13-4.el7.x86_64                                                                                                                                                                                                                               1/3 
  Verifying  : dracut-fips-033-554.el7.x86_64                                                                                                                                                                                                                             2/3 
  Verifying  : dracut-fips-aesni-033-554.el7.x86_64                                                                                                                                                                                                                       3/3 

Installed:
  dracut-fips.x86_64 0:033-554.el7                                                        dracut-fips-aesni.x86_64 0:033-554.el7                                                        hmaccalc.x86_64 0:0.9.13-4.el7                                                       

Complete!
Cleaning up completed transaction file
[root@storage ~]#

rpmdb는 왜 이리도 깨지는 것일까? 이유는 무엇일까?

[root@deployer playbooks]# cat setup-hosts.yml 
---
# Copyright 2014, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- include: openstack-hosts-setup.yml
# - include: security-hardening.yml
- include: containers-deploy.yml
[root@deployer playbooks]# 

/etc/hosts 가 문제였을까?
aio으로 설치되었던 잔재가 문제가 되었을 소지가 있다. 

- [X] add more memory and cpu to compute
  - kswapd0 또 올라왔다. 

#+BEGIN_SRC 
top - 15:18:29 up  1:50,  1 user,  load average: 4.15, 3.03, 2.07
Tasks: 348 total,   6 running, 342 sleeping,   0 stopped,   0 zombie
%Cpu(s): 93.4 us,  5.3 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi,  1.2 si,  0.0 st
KiB Mem :  1881840 total,    82308 free,   745796 used,  1053736 buff/cache
KiB Swap:  1572860 total,  1464564 free,   108296 used.   845500 avail Mem 

  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND                                                                                    
23559 root      20   0  414184 112496   9464 R  91.4  6.0   0:12.10 python   
#+END_SRC

- [X] care about facts at /etc/openstack_deploy/ansible_facts/
  - 25일 어제 밤 9시 34분에서 부터

다시 또 다시 그리고 또 다시다.

ls
ls -l
ls -al
ls -ltr
ls -altr
ls -lR
ls -lR | grep x


- [X] 개별서버의 /etc/hosts도 확인 필요하다, 제거 대상인가?
- [ ] lxc howto

* then again

- [X] openstack-ansible setup-infrastructure.yml --syntax-check
- [ ] openstack-ansible setup-hosts.yml

infra1 is the 'control' but who name it?
compute1
storage1

ASK [Ensure python is installed] ******************************************************************************************************************************
Friday 26 July 2019  15:30:34 +0900 (0:00:01.871)       0:00:01.871 *********** 
ok: [infra1]
ok: [compute1]
ok: [storage1]
fatal: [aio1]: UNREACHABLE! => {"changed": false, "msg": "Failed to connect to the host via ssh: ssh: connect to host 172.29.236.100 port 22: No route to host\r\n", "unreachable": true}


/tmp/

TASK [Ensure python is installed] ******************************************************************************************************************************
Friday 26 July 2019  15:36:09 +0900 (0:00:01.239)       0:00:01.239 *********** 
ok: [compute1]
ok: [infra1]
ok: [storage1]
fatal: [aio1]: UNREACHABLE! => {"changed": false, "msg": "Failed to connect to the host via ssh: 
ssh: connect to host 172.29.236.100 port 22: No route to host\r\n", "unreachable": true}



- name: Install Ansible prerequisites
  hosts: "{{ openstack_host_group|default('hosts') }}"
  gather_facts: false
  user: root
  pre_tasks:
    - name: Ensure python is installed
      register: result
      raw: |
        if which apt-get >/dev/null && ! which python >/dev/null ; then
          apt-get -y install python
          exit 2
        else
          exit 0
        fi
      changed_when: "result.rc == 2"
      failed_when: "result.rc not in [0, 2]"



https://stackoverflow.com/questions/42971296/usage-of-variable-and-role-in-openstack-ansible

* then again, 다시

- [X] script/bootstrap-ansible.sh
- [X] openstack-ansible setup-infrastructure.yml --syntax-check
- [ ] openstack-ansible setup-hosts.yml

이제는 Ensure python is installed에서 aio1에 대한 실패는 뜨지 않겠지? 인데
서 있다. 설마!

또 떴다. aio1 그리고 172.29.236.100

rpm 또 깨질까? 그러면 그때 comment

# Bind the External VIP
auto br-mgmt:0
iface br-mgmt:0 inet static
    address 172.29.236.10
    netmask 255.255.252.0

global_overrides:
  # The internal and external VIP should be different IPs, however they
  # do not need to be on separate networks.
  external_lb_vip_address: 172.29.236.10

https://docs.openstack.org/openstack-ansible/queens/user/test/example.html


[root@deployer openstack_deploy]# cat /etc/sysconfig/network-scripts/ifcfg-br-mgmt 
BOOTPROTO=none
ONBOOT=yes
DEVICE=br-mgmt
TYPE=Bridge
IPADDR=172.29.236.3
PREFIX=22
[root@deployer openstack_deploy]# 

https://ma.ttias.be/how-to-add-secondary-ip-alias-on-network-interface-in-rhel-centos-7/

# cat /etc/sysconfig/network-scripts/ifcfg-br-mgmt:0
BOOTPROTO=none
ONBOOT=yes
DEVICE=br-mgmt:0
TYPE=Bridge
IPADDR=172.29.236.10
PREFIX=22

그런데 어디에 두어야 하는가?

TASK [Ensure python is installed] ********************************************************************************************************************************************************************************************************************************************
task path: /opt/openstack-ansible/playbooks/openstack-hosts-setup.yml:27
Friday 26 July 2019  16:47:53 +0900 (0:00:01.302)       0:00:01.302 *********** 
<aio1> The "physical_host" variable of "aio1" has been found to have a corresponding host entry in inventory.
<aio1> The "physical_host" variable of "aio1" terminates at "172.29.236.100" using the host variable "ansible_host".
container_name: "aio1"
physical_host: "aio1"
container_name: "aio1"
physical_host: "aio1"
<172.29.236.100> ESTABLISH SSH CONNECTION FOR USER: root
<172.29.236.100> SSH: EXEC ssh -C -o ControlMaster=auto -o ControlPersist=60s -o StrictHostKeyChecking=no -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o User=root -o ConnectTimeout=5 -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no -o ServerAliveInterval=64 -o ServerAliveCountMax=1024 -o Compression=no -o TCPKeepAlive=yes -o VerifyHostKeyDNS=no -o ForwardX11=no -o ForwardAgent=yes -T -o ControlPath=/root/.ansible/cp/53b4b74265 -tt 172.29.236.100 'if which apt-get >/dev/null && ! which python >/dev/null ; then
 apt-get -y install python
 exit 2
 else
 exit 0
 fi'


https://docs.openstack.org/openstack-ansible/pike/reference/manage-inventory.html

[root@deployer openstack_deploy]# cat openstack_inventory.json.old | grep 100
                "ansible_host": "172.29.236.100",
		

https://docs.openstack.org/openstack-ansible/latest/reference/inventory/manage-inventory.html

Never edit or delete the files /etc/openstack_deploy/openstack_inventory.json or /etc/openstack_deploy/openstack_hostnames_ips.yml. This can lead to file corruptions, and problems with the inventory: hosts and container could disappear and new ones would appear, breaking your existing deployment.

/etc/openstack-x
/opt/openstack-x

cleaning then again

* again from the beginning without reinstall os

nop more control compute storage related task except rpm

- [X] using pre.sh
- [X] openstack-ansible setup-infrastructure.yml --syntax-check

rpm broken

rm -f /var/lib/rpm/__db.00*
rpm --rebuilddb

nop hardening

- [ ] openstack-ansible setup-hosts.yml

nop disk space 50 to 30

이런 아래 때문일까?

TASK [lxc_container_create : Run container veth wiring script] *************************************************************************************************
Friday 26 July 2019  17:33:19 +0900 (0:00:10.897)       0:15:11.674 *********** 
 [WARNING]: sftp transfer mechanism failed on [172.29.236.11]. Use ANSIBLE_DEBUG=1 to see detailed information

 [WARNING]: scp transfer mechanism failed on [172.29.236.11]. Use ANSIBLE_DEBUG=1 to see detailed information

failed: [infra1_keystone_container-3c65c331] (item={'value': {u'interface': u'eth1', u'bridge': u'br-mgmt', u'netmask': u'255.255.252.0', u'type': u'veth', u'address': u'172.29.236.60'}, 'key': u'container_address'}) => {"item": {"key": "container_address", "value": {"address": "172.29.236.60", "bridge": "br-mgmt", "interface": "eth1", "netmask": "255.255.252.0", "type": "veth"}}, "msg": "Failed to connect to the host via ssh: ssh: connect to host 172.29.236.11 port 22: Connection timed out\r\n", "unreachable": true}
fatal: [infra1_keystone_container-3c65c331]: UNREACHABLE! => {"changed": false, "msg": "All items completed", "results": [{"_ansible_ignore_errors": null, "_ansible_item_result": true, "item": {"key": "container_address", "value": {"address": "172.29.236.60", "bridge": "br-mgmt", "interface": "eth1", "netmask": "255.255.252.0", "type": "veth"}}, "msg": "Failed to connect to the host via ssh: ssh: co

[root@deployer openstack_deploy]# cp user_variables.yml.test.example user_variables.yml
cp: overwrite ‘user_variables.yml’? y
[root@deployer openstack_deploy]# vi user_variables.yml
[root@deployer openstack_deploy]# 

ANSIBLE_DEBUG=1

# openstack-ansible setup-infrastructure.yml --syntax-check
Variable files: "-e @/etc/openstack_deploy/user_secrets.yml -e @/etc/openstack_deploy/user_variables.yml "
 [WARNING]: Unable to parse /etc/openstack_deploy/inventory.ini as an inventory source



 [WARNING]: Could not match supplied host pattern, ignoring: unbound
 [WARNING]: Could not match supplied host pattern, ignoring: repo_masters
 [WARNING]: Could not match supplied host pattern, ignoring: etcd_all
 [WARNING]: Could not match supplied host pattern, ignoring: ceph-mon
 [WARNING]: Could not match supplied host pattern, ignoring: ceph-osd
 [WARNING]: Could not match supplied host pattern, ignoring: rsyslog



TASK [Ensure python is installed] ******************************************************************
Friday 26 July 2019  21:22:25 +0900 (0:00:00.703)       0:00:00.703 *********** 
fatal: [compute1]: UNREACHABLE! => {"changed": false, "msg": "Failed to connect to the host via ssh: ssh: connect to host 172.29.236.12 port 22: No route to host\r\n", "unreachable": true}
fatal: [infra1]: UNREACHABLE! => {"changed": false, "msg": "Failed to connect to the host via ssh: ssh: connect to host 172.29.236.11 port 22: No route to host\r\n", "unreachable": true}
fatal: [storage1]: UNREACHABLE! => {"changed": false, "msg": "Failed to connect to the host via ssh: ssh: connect to host 172.29.236.13 port 22: No route to host\r\n", "unreachable": true}

PLAY RECAP *****************************************************************************************
compute1                   : ok=0    changed=0    unreachable=1    failed=0   
infra1                     : ok=0    changed=0    unreachable=1    failed=0   
storage1                   : ok=0    changed=0    unreachable=1    failed=0   

Friday 26 July 2019  21:23:09 +0900 (0:00:44.547)       0:00:45.251 *********** 
=============================================================================== 
Ensure python is installed ----------------------------------------------------------------- 44.55s

EXIT NOTICE [Playbook execution failure] **************************************
===============================================================================


따라갈 수 없다. 눈 튀어나오겠다.
오늘 몇시부터 몇시까지 봤는지 모르겠다.
어쨌거나 녹색이 많이 나온다. 하얀색 그리고 녹색 좋은 로그다.

하얀색은? description and timestamp
TASK [lxc_hosts : Add image cache] ****************
Friday 26 July 2019  21:33:16 +0900 (0:00:00.925) 0:05:04:803

녹색은? 
ok: [infra1] => (item=logrotate)

노란색은? 
changed: [infra1]

푸른색은? 
include: /etc/ansible/roles/lxc_hosts/tasks/lxc_cache_preparation>systemd_old.yml for infra1
skipping: [infra1_rabbit_mq_container_x]

보라색은?

짙은 보라색은?

흑색은? 
FAILED - RETRYING: Ensure image has been pre-staged (60 retries left).

WARNING! The remote SSH server rejected X11 forwarding request.
Last login: Fri Jul 26 21:36:13 2019 from 192.168.100.1
------------------------------------------------------------------------------
* WARNING                                                                    *
* You are accessing a secured system and your actions will be logged along   *
* with identifying information. Disconnect immediately if you are not an     *
* authorized user of this system.                                            *
------------------------------------------------------------------------------

# cat /etc/ssh/sshd_config  | grep ^Banner
Banner /etc/motd

infra aka control 한참 설치 중에 들어가서 보니 
메모리 8g 중 4g 사용 중이다.
cpus는 20% 이하로 나온다. 좋다.

Friday 26 July 2019  21:59:41 +0900 (0:00:01.597)       0:31:30.193 *********** 
=============================================================================== 
pip_install : Install distro packages --------------------------------------------------------------------------- 234.25s
lxc_hosts : Ensure image has been pre-staged -------------------------------------------------------------------- 203.83s
openstack_hosts : Add requirement packages (repositories gpg keys packages, toolkits...) ------------------------ 196.86s
pip_install : Install PIP --------------------------------------------------------------------------------------- 106.75s
lxc_hosts : Ensure that the LXC cache has been prepared ---------------------------------------------------------- 96.81s
lxc_hosts : Place container rootfs ------------------------------------------------------------------------------- 63.33s
lxc_container_create : Write default container config ------------------------------------------------------------ 50.56s
pip_install : Get Modern PIP ------------------------------------------------------------------------------------- 48.18s
lxc_hosts : Ensure createrepo package is installed --------------------------------------------------------------- 41.32s
lxc_container_create : Container service directories ------------------------------------------------------------- 24.39s
lxc_container_create : Run container veth wiring script ---------------------------------------------------------- 22.16s
lxc_hosts : Create lxc image ------------------------------------------------------------------------------------- 21.51s
openstack_hosts : Adding new system tuning ----------------------------------------------------------------------- 21.35s
openstack_hosts : Load kernel module(s) -------------------------------------------------------------------------- 18.73s
lxc_container_create : Read custom facts from previous runs ------------------------------------------------------ 14.84s
pip_install : Install PIP ---------------------------------------------------------------------------------------- 14.46s
lxc_container_create : Drop veth cleanup script ------------------------------------------------------------------ 13.45s
openstack_hosts : If a keyfile is provided, copy the gpg keyfile to the key location ----------------------------- 13.26s
openstack_hosts : Drop hosts file entries script locally --------------------------------------------------------- 12.83s
lxc_container_create : LXC host config for container networks ---------------------------------------------------- 12.59s

EXIT NOTICE [Playbook execution success] **************************************
===============================================================================
? openstack-ansible setup-hosts.yml 

된것가 여기까지는 말이다.

? openstack-ansible setup-infrastructure.yml

이다. 

infra aka control 한참 설치 중에 들어가서 보니 
메모리 8g 중 4g free다. > 600m free다.
cpus는 20% 이하로 나온다. 좋다. > 최고 100%도 친다. 그래도 낮게 나온다. 

시간은 오래 걸린다 언제 끝이 날까?

1:16:15:242



ASK [galera_client : Install galera distro packages] ********************************************************************
Friday 26 July 2019  23:18:07 +0900 (0:00:00.659)       1:16:15.242 *********** 

TASK [galera_server : Fail if the galera root password is not provided] **************************************************
Friday 26 July 2019  23:32:25 +0900 (0:00:00.023)       1:30:33.507 *********** 
fatal: [infra1_galera_container-5103f3b8]: FAILED! => {"changed": false, "failed": true, "msg": "Please set the galera_root_password variable prior to applying the\ngalera role.\n"}

PLAY RECAP ***************************************************************************************************************
compute1                   : ok=18   changed=3    unreachable=0    failed=0   
infra1                     : ok=52   changed=25   unreachable=0    failed=0   
infra1_cinder_api_container-179eba5a : ok=9    changed=3    unreachable=0    failed=0   
infra1_galera_container-5103f3b8 : ok=20   changed=8    unreachable=0    failed=1   
infra1_glance_container-9e87261d : ok=9    changed=3    unreachable=0    failed=0   
infra1_heat_api_container-1e3d12d9 : ok=9    changed=3    unreachable=0    failed=0   
infra1_horizon_container-280f6f5a : ok=9    changed=3    unreachable=0    failed=0   
infra1_keystone_container-3c65c331 : ok=9    changed=3    unreachable=0    failed=0   
infra1_memcached_container-21e6d45f : ok=40   changed=22   unreachable=0    failed=0   
infra1_neutron_server_container-47a7eec0 : ok=9    changed=3    unreachable=0    failed=0   
infra1_nova_api_container-758f0659 : ok=9    changed=3    unreachable=0    failed=0   
infra1_rabbit_mq_container-76ec7893 : ok=9    changed=3    unreachable=0    failed=0   
infra1_repo_container-a2b512e9 : ok=176  changed=78   unreachable=0    failed=0   
infra1_utility_container-8de920e2 : ok=36   changed=20   unreachable=0    failed=0   
localhost                  : ok=1    changed=1    unreachable=0    failed=0   
storage1                   : ok=9    changed=3    unreachable=0    failed=0   

Friday 26 July 2019  23:32:25 +0900 (0:00:00.082)       1:30:33.590 *********** 
=============================================================================== 
repo_build : Create OpenStack-Ansible requirement wheels ------------------------------------------------------- 2445.79s
repo_build : Wait for the venvs builds to complete -------------------------------------------------------------- 792.19s
galera_client : Install galera distro packages ------------------------------------------------------------------ 661.04s
repo_build : Clone git repositories ----------------------------------------------------------------------------- 523.33s
galera_client : Install galera distro packages ------------------------------------------------------------------ 229.32s
memcached_server : Install distro packages ----------------------------------------------------------------------- 82.13s
repo_build : Install packages ------------------------------------------------------------------------------------ 53.20s
Install pip packages --------------------------------------------------------------------------------------------- 50.43s
repo_server : Install pip packages (from repo) ------------------------------------------------------------------- 35.12s
repo_server : Install distro packages ---------------------------------------------------------------------------- 34.20s
repo_build : Install pip packages (from repo) -------------------------------------------------------------------- 32.20s
repo_build : Execute the venv build scripts asynchonously -------------------------------------------------------- 29.20s
haproxy_server : Create haproxy service config files ------------------------------------------------------------- 28.73s
haproxy_server : Install HAProxy Packages ------------------------------------------------------------------------ 24.08s
repo_server : Install required pip packages (from repo) ---------------------------------------------------------- 19.98s
repo_build : Create venv build options files --------------------------------------------------------------------- 14.96s
pip_install : Install PIP ---------------------------------------------------------------------------------------- 10.98s
pip_install : Install PIP ---------------------------------------------------------------------------------------- 10.96s
Install distro packages ------------------------------------------------------------------------------------------- 8.58s
repo_server : File and directory setup (non-root user) ------------------------------------------------------------ 7.79s

EXIT NOTICE [Playbook execution failure] **************************************
===============================================================================
? 



- name: Fail if the galera root password is not provided
  fail:
    msg: |
      Please set the galera_root_password variable prior to applying the
      galera role.
  when: (galera_root_password is undefined) or (galera_root_password is none)
  tags:
    - always



grep -r galera_root_password *

? ./scripts/pw-token-gen.py --file /etc/openstack_deploy/user_secrets.yml
Creating backup file [ /etc/openstack_deploy/user_secrets.yml.tar ]
Operation Complete, [ /etc/openstack_deploy/user_secrets.yml ] is ready
? pwd
/opt/openstack-ansible
? 


? diff user_secrets.yml.orig user_secrets.yml | grep galera_root_password
< galera_root_password:
> galera_root_password: dcf6eb7100fb1f42ecb2
? 

* galera then again

[2019-07-26 금 23:41] 오늘은 이만하고 잘까? 이건 어쩌나? 두면 될까? 얼마나 걸리려나?
* done

PLAY [Ensure rabbitmq user for monitoring GUI] ***************************************************************************

TASK [Create rabbitmq user for monitoring GUI] ***************************************************************************
Saturday 27 July 2019  00:21:01 +0900 (0:00:00.438)       0:40:02.521 ********* 
changed: [infra1_rabbit_mq_container-76ec7893]
 [WARNING]: Could not match supplied host pattern, ignoring: etcd_all


PLAY [Install etcd server cluster] ***************************************************************************************
skipping: no hosts matched
 [WARNING]: Could not match supplied host pattern, ignoring: ceph-mon


PLAY [Install ceph mons] *************************************************************************************************
skipping: no hosts matched
 [WARNING]: Could not match supplied host pattern, ignoring: ceph-osd


PLAY [Install ceph osds] *************************************************************************************************
skipping: no hosts matched
 [WARNING]: Could not match supplied host pattern, ignoring: rsyslog


PLAY [Install rsyslog] ***************************************************************************************************
skipping: no hosts matched

PLAY RECAP ***************************************************************************************************************
compute1                   : ok=18   changed=0    unreachable=0    failed=0   
infra1                     : ok=48   changed=0    unreachable=0    failed=0   
infra1_cinder_api_container-179eba5a : ok=9    changed=0    unreachable=0    failed=0   
infra1_galera_container-5103f3b8 : ok=83   changed=40   unreachable=0    failed=0   
infra1_glance_container-9e87261d : ok=9    changed=0    unreachable=0    failed=0   
infra1_heat_api_container-1e3d12d9 : ok=9    changed=0    unreachable=0    failed=0   
infra1_horizon_container-280f6f5a : ok=9    changed=0    unreachable=0    failed=0   
infra1_keystone_container-3c65c331 : ok=9    changed=0    unreachable=0    failed=0   
infra1_memcached_container-21e6d45f : ok=34   changed=1    unreachable=0    failed=0   
infra1_neutron_server_container-47a7eec0 : ok=9    changed=0    unreachable=0    failed=0   
infra1_nova_api_container-758f0659 : ok=9    changed=0    unreachable=0    failed=0   
infra1_rabbit_mq_container-76ec7893 : ok=84   changed=41   unreachable=0    failed=0   
infra1_repo_container-a2b512e9 : ok=143  changed=8    unreachable=0    failed=0   
infra1_utility_container-8de920e2 : ok=32   changed=5    unreachable=0    failed=0   
localhost                  : ok=1    changed=1    unreachable=0    failed=0   
storage1                   : ok=9    changed=0    unreachable=0    failed=0   

Saturday 27 July 2019  00:21:16 +0900 (0:00:14.346)       0:40:16.867 ********* 
=============================================================================== 
galera_server : Install galera_server role remote packages ----------------------------------------------------- 1627.36s
rabbitmq_server : Ensure RabbitMQ node [0] is stopped ------------------------------------------------------------ 95.15s
rabbitmq_server : Install RabbitMQ packages ---------------------------------------------------------------------- 41.08s
haproxy_server : Create haproxy service config files ------------------------------------------------------------- 27.78s
rabbitmq_server : Configure rabbitmq plugins --------------------------------------------------------------------- 22.86s
rabbitmq_server : Ensure RabbitMQ node [0] is started ------------------------------------------------------------ 22.44s
rabbitmq_server : Ensure RabbitMQ node [0] is started ------------------------------------------------------------ 19.84s
rabbitmq_server : Ensure RabbitMQ node [0] is started ------------------------------------------------------------ 17.11s
rabbitmq_server : Install yum versionlock plugin ----------------------------------------------------------------- 16.97s
rabbitmq_server : Ensure default rabbitmq guest user is removed -------------------------------------------------- 14.47s
Create rabbitmq user for monitoring GUI -------------------------------------------------------------------------- 14.35s
galera_server : Run galera secure -------------------------------------------------------------------------------- 13.84s
haproxy_server : Install HAProxy Packages ------------------------------------------------------------------------ 12.46s
galera_server : Apply systemd options ---------------------------------------------------------------------------- 11.51s
rabbitmq_server : Ensure RabbitMQ node [0] is stopped ------------------------------------------------------------ 11.24s
pip_install : Install PIP ---------------------------------------------------------------------------------------- 10.99s
repo_build : Create venv build options files --------------------------------------------------------------------- 10.70s
galera_server : Start new cluster -------------------------------------------------------------------------------- 10.55s
haproxy_server : Remove haproxy service config files for absent services ------------------------------------------ 9.60s
repo_build : Install packages ------------------------------------------------------------------------------------- 7.54s

EXIT NOTICE [Playbook execution success] **************************************
===============================================================================
You have mail in /var/spool/mail/root
? timed out waiting for input: auto-logout
[vagrant@deployer ~]$ 


앗 아직이다.




[root@deployer playbooks]# openstack-ansible setup-openstack.yml 


TASK [os_nova : Install required pip packages] ***************************************************************************
Saturday 27 July 2019  01:06:11 +0900 (0:00:00.032)       0:24:45.984 ********* 

TASK [os_nova : Set SELinux file contexts for nova's ssh keys] ***********************************************************
Saturday 27 July 2019  01:07:18 +0900 (0:00:00.087)       0:25:53.501 ********* 
fatal: [compute1]: FAILED! => {"changed": false, "failed": true, "msg": "This module requires policycoreutils-python"}

RUNNING HANDLER [os_nova : Stop services] ********************************************************************************
Saturday 27 July 2019  01:07:19 +0900 (0:00:00.610)       0:25:54.111 ********* 
FAILED - RETRYING: Stop services (5 retries left).
FAILED - RETRYING: Stop services (4 retries left).
FAILED - RETRYING: Stop services (3 retries left).
FAILED - RETRYING: Stop services (2 retries left).
FAILED - RETRYING: Stop services (1 retries left).
failed: [compute1] (item={u'init_config_overrides': {}, u'service_name': u'nova-compute', u'start_order': 5, u'group': u'nova_compute', 'service_key': u'nova-compute'}) => {"attempts": 5, "changed": false, "failed": true, "item": {"group": "nova_compute", "init_config_overrides": {}, "service_key": "nova-compute", "service_name": "nova-compute", "start_order": 5}, "msg": "Could not find the requested service nova-compute: host"}

RUNNING HANDLER [os_nova : Copy new policy file into place] **************************************************************
Saturday 27 July 2019  01:07:32 +0900 (0:00:12.694)       0:26:06.806 ********* 

RUNNING HANDLER [os_nova : Remove legacy policy.json file] ***************************************************************
Saturday 27 July 2019  01:07:32 +0900 (0:00:00.034)       0:26:06.841 ********* 
ok: [compute1]

RUNNING HANDLER [os_nova : Start services] *******************************************************************************
Saturday 27 July 2019  01:07:32 +0900 (0:00:00.369)       0:26:07.211 ********* 
FAILED - RETRYING: Start services (5 retries left).
FAILED - RETRYING: Start services (4 retries left).
FAILED - RETRYING: Start services (3 retries left).
FAILED - RETRYING: Start services (2 retries left).
FAILED - RETRYING: Start services (1 retries left).
failed: [compute1] (item={u'init_config_overrides': {}, u'service_name': u'nova-compute', u'start_order': 5, u'group': u'nova_compute', 'service_key': u'nova-compute'}) => {"attempts": 5, "changed": false, "failed": true, "item": {"group": "nova_compute", "init_config_overrides": {}, "service_key": "nova-compute", "service_name": "nova-compute", "start_order": 5}, "msg": "Could not find the requested service nova-compute: host"}

RUNNING HANDLER [os_nova : Wait for the nova-compute service to initialize] **********************************************
Saturday 27 July 2019  01:07:45 +0900 (0:00:12.645)       0:26:19.857 ********* 
skipping: [compute1]

RUNNING HANDLER [os_nova : meta] *****************************************************************************************
Saturday 27 July 2019  01:07:45 +0900 (0:00:00.133)       0:26:19.990 ********* 

PLAY RECAP ***************************************************************************************************************
compute1                   : ok=37   changed=21   unreachable=0    failed=3   
infra1_cinder_api_container-179eba5a : ok=107  changed=58   unreachable=0    failed=0   
infra1_glance_container-9e87261d : ok=86   changed=52   unreachable=0    failed=0   
infra1_keystone_container-3c65c331 : ok=123  changed=66   unreachable=0    failed=0   
infra1_nova_api_container-758f0659 : ok=98   changed=60   unreachable=0    failed=0   
storage1                   : ok=72   changed=43   unreachable=0    failed=0   

Saturday 27 July 2019  01:07:45 +0900 (0:00:00.022)       0:26:20.013 ********* 
=============================================================================== 
os_nova : Install distro packages ------------------------------------------------------------------------------- 188.37s
Perform online data migrations ----------------------------------------------------------------------------------- 66.99s
os_cinder : Install distro packages ------------------------------------------------------------------------------ 65.97s
os_keystone : Install distro packages ---------------------------------------------------------------------------- 56.95s
os_nova : Install required pip packages -------------------------------------------------------------------------- 37.00s
os_nova : Synchronize the nova DB schema ------------------------------------------------------------------------- 33.08s
os_cinder : Ensure cinder api is available ----------------------------------------------------------------------- 32.60s
os_cinder : Install distro packages ------------------------------------------------------------------------------ 30.99s
os_glance : Install distro packages ------------------------------------------------------------------------------ 29.85s
os_nova : Install distro packages -------------------------------------------------------------------------------- 28.45s
os_nova : Install required pip packages -------------------------------------------------------------------------- 27.53s
os_keystone : Wait for web server to complete starting ----------------------------------------------------------- 21.32s
os_keystone : Wait for uWSGI socket to be ready ------------------------------------------------------------------ 21.22s
Ensure rabbitmq user --------------------------------------------------------------------------------------------- 20.34s
Ensure rabbitmq user --------------------------------------------------------------------------------------------- 17.36s
Ensure rabbitmq user --------------------------------------------------------------------------------------------- 16.69s
Ensure rabbitmq user --------------------------------------------------------------------------------------------- 15.63s
os_cinder : Install requires pip packages ------------------------------------------------------------------------ 15.53s
Ensure Rabbitmq vhost -------------------------------------------------------------------------------------------- 14.13s
os_nova : Unarchive pre-built venv ------------------------------------------------------------------------------- 13.93s

EXIT NOTICE [Playbook execution failure] **************************************
===============================================================================
[root@deployer playbooks]# 

[root@compute ~]# yum install policycoreutils-python -y

어 이거 그분이 올려놓은 글에서 확인한 내용인데

오래 걸린다. 이유는

control 8g 중 150m free, cpu hot with python, swap 427m using
compute 2g 중 822m free . 504m free.
storage 2g 중 645m free

[vagrant@compute ~]$ pstree -p
systemd(1)─┬─VBoxService(833)─┬─{VBoxService}(835)
           │                  ├─{VBoxService}(836)
           │                  ├─{VBoxService}(837)
           │                  ├─{VBoxService}(838)
           │                  ├─{VBoxService}(839)
           │                  ├─{VBoxService}(840)
           │                  └─{VBoxService}(841)
           ├─agetty(736)
           ├─auditd(646)───{auditd}(647)
           ├─chronyd(689)
           ├─crond(729)
           ├─dbus-daemon(680)───{dbus-daemon}(705)
           ├─dhclient(1049)
           ├─gssproxy(696)─┬─{gssproxy}(697)
           │               ├─{gssproxy}(698)
           │               ├─{gssproxy}(699)
           │               ├─{gssproxy}(700)
           │               └─{gssproxy}(701)
           ├─irqbalance(711)
           ├─libvirtd(8117)─┬─{libvirtd}(8118)
           │                ├─{libvirtd}(8119)
           │                ├─{libvirtd}(8120)
           │                ├─{libvirtd}(8121)
           │                ├─{libvirtd}(8122)
           │                ├─{libvirtd}(8123)
           │                ├─{libvirtd}(8124)
           │                ├─{libvirtd}(8125)
           │                ├─{libvirtd}(8126)
           │                ├─{libvirtd}(8127)
           │                ├─{libvirtd}(8128)
           │                ├─{libvirtd}(8129)
           │                ├─{libvirtd}(8130)
           │                ├─{libvirtd}(8131)
           │                ├─{libvirtd}(8132)
           │                └─{libvirtd}(8137)
           ├─lvmetad(492)


[vagrant@storage ~]$ pstree -p
systemd(1)─┬─VBoxService(834)─┬─{VBoxService}(836)
           │                  ├─{VBoxService}(837)
           │                  ├─{VBoxService}(838)
           │                  ├─{VBoxService}(839)
           │                  ├─{VBoxService}(840)
           │                  ├─{VBoxService}(841)
           │                  └─{VBoxService}(842)
           ├─agetty(728)
           ├─auditd(649)───{auditd}(650)
           ├─chronyd(696)
           ├─cinder-volume(6312)───cinder-volume(6323)


[vagrant@control ~]$ pstree
systemd─┬─VBoxService───7*[{VBoxService}]
        ├─agetty
        ├─auditd───{auditd}
        ├─chronyd
        ├─crond
        ├─dbus-daemon───{dbus-daemon}
        ├─dhclient
        ├─dnsmasq
        ├─gssproxy───5*[{gssproxy}]
        ├─haproxy-systemd───haproxy───haproxy
        ├─irqbalance
        ├─lvmetad
        ├─14*[lxc-autostart───systemd─┬─5*[agetty]]
        │                             ├─crond]
        │                             ├─dbus-daemon]
        │                             ├─dhclient]
        │                             ├─rsyslogd───2*[{rsyslogd}]]
        │                             ├─sshd]
        │                             ├─systemd-journal]
        │                             └─systemd-logind]
        ├─lxc-start───systemd─┬─5*[agetty]
        │                     ├─anacron
        │                     ├─crond
        │                     ├─dbus-daemon
        │                     ├─dhclient
        │                     ├─rsyslogd───4*[{rsyslogd}]
        │                     ├─sshd
        │                     ├─systemd-journal
        │                     ├─systemd-logind
        │                     └─uwsgi───8*[uwsgi]
        ├─lxc-start───systemd─┬─5*[agetty]
        │                     ├─cinder-schedule
        │                     ├─crond
        │                     ├─dbus-daemon
        │                     ├─dhclient
        │                     ├─rsyslogd───4*[{rsyslogd}]
        │                     ├─sshd
        │                     ├─systemd-journal
        │                     ├─systemd-logind
        │                     └─uwsgi───9*[uwsgi]
        ├─lxc-start───systemd─┬─5*[agetty]
        │                     ├─beam.smp─┬─erl_child_setup───inet_gethost───inet_gethost
        │                     │          └─135*[{beam.smp}]
        │                     ├─crond
        │                     ├─dbus-daemon
        │                     ├─dhclient
        │                     ├─epmd
        │                     ├─rsyslogd───4*[{rsyslogd}]
        │                     ├─sshd
        │                     ├─systemd-journal
        │                     └─systemd-logind
        ├─2*[lxc-start───systemd─┬─5*[agetty]]
        │                        ├─crond]
        │                        ├─dbus-daemon]
        │                        ├─dhclient]
        │                        ├─rsyslogd───2*[{rsyslogd}]]
        │                        ├─sshd]
        │                        ├─systemd-journal]
        │                        └─systemd-logind]
        ├─lxc-start───systemd─┬─5*[agetty]
        │                     ├─crond
        │                     ├─dbus-daemon
        │                     ├─dhclient
        │                     ├─nova-conductor───2*[nova-conductor]
        │                     ├─nova-consoleaut
        │                     ├─nova-scheduler
        │                     ├─nova-spicehtml5
        │                     ├─rsyslogd───4*[{rsyslogd}]
        │                     ├─sshd
        │                     ├─systemd-journal
        │                     ├─systemd-logind
        │                     └─3*[uwsgi───9*[uwsgi]]
        ├─lxc-start───systemd─┬─5*[agetty]
        │                     ├─anacron
        │                     ├─crond
        │                     ├─dbus-daemon
        │                     ├─dhclient
        │                     ├─nginx───4*[nginx]
        │                     ├─rsyslogd───4*[{rsyslogd}]
        │                     ├─sshd
        │                     ├─systemd-journal
        │                     ├─systemd-logind
        │                     └─2*[uwsgi───9*[uwsgi]]
        ├─lxc-start───systemd─┬─5*[agetty]
        │                     ├─crond
        │                     ├─dbus-daemon
        │                     ├─dhclient
        │                     ├─memcached───9*[{memcached}]
        │                     ├─rsyslogd───3*[{rsyslogd}]
        │                     ├─sshd
        │                     ├─systemd-journal
        │                     └─systemd-logind
        ├─lxc-start───systemd─┬─5*[agetty]
        │                     ├─crond
        │                     ├─dbus-daemon
        │                     ├─dhclient
        │                     ├─mysqld───77*[{mysqld}]
        │                     ├─rsyslogd───4*[{rsyslogd}]
        │                     ├─sshd
        │                     ├─systemd-journal
        │                     ├─systemd-logind
        │                     └─xinetd
        ├─lxc-start───systemd─┬─5*[agetty]
        │                     ├─apt-cacher-ng───8*[{apt-cacher-ng}]
        │                     ├─crond
        │                     ├─dbus-daemon
        │                     ├─dhclient
        │                     ├─nginx───2*[nginx]
        │                     ├─pypi-server───237*[{pypi-server}]
        │                     ├─rsync
        │                     ├─rsyslogd───4*[{rsyslogd}]
        │                     ├─sshd
        │                     ├─systemd-journal
        │                     └─systemd-logind
        ├─master─┬─pickup
        │        └─qmgr
        ├─polkitd───6*[{polkitd}]
        ├─rpcbind
        ├─rsyslogd───5*[{rsyslogd}]
        ├─sshd─┬─sshd───lxc-attach───su───sh───sudo───sh───python───python───neutron-db-mana
        │      └─sshd───sshd───bash───pstree
        ├─systemd-journal
        ├─systemd-logind
        ├─systemd-udevd
        └─tuned───4*[{tuned}]
[vagrant@control ~]$ 


[vagrant@control ~]$ brctl show
bridge name	bridge id		STP enabled	interfaces
br-mgmt		8000.0800277bd9b7	no		0674895c_eth1
							11734601_eth1
							179eba5a_eth1
							1dbe0b7a_eth1
							1de92927_eth1
							1e3d12d9_eth1
							21e6d45f_eth1
							280f6f5a_eth1
							3c65c331_eth1
							3ca87b11_eth1
							47a7eec0_eth1
							5103f3b8_eth1
							6d9d4294_eth1
							758f0659_eth1
							76ec7893_eth1
							7d277f71_eth1
							8de920e2_eth1
							9e87261d_eth1
							a2b512e9_eth1
							af9f1617_eth1
							c34abfbe_eth1
							ed0fcd59_eth1
							eth2
							f34593d8_eth1
							fbd3b559_eth1
br-storage		8000.080027578616	no		179eba5a_eth2
							6d9d4294_eth2
							9e87261d_eth2
							ed0fcd59_eth2
							eth3
br-vlan		8000.08002773a6ad	no		eth5
br-vxlan		8000.08002705c2db	no		eth4
lxcbr0		8000.fe018eacb221	no		0674895c_eth0
							11734601_eth0
							179eba5a_eth0
							1dbe0b7a_eth0
							1de92927_eth0
							1e3d12d9_eth0
							21e6d45f_eth0
							280f6f5a_eth0
							3c65c331_eth0
							3ca87b11_eth0
							47a7eec0_eth0
							5103f3b8_eth0
							6d9d4294_eth0
							758f0659_eth0
							76ec7893_eth0
							7d277f71_eth0
							8de920e2_eth0
							9e87261d_eth0
							a2b512e9_eth0
							af9f1617_eth0
							c34abfbe_eth0
							ed0fcd59_eth0
							f34593d8_eth0
							fbd3b559_eth0
[vagrant@control ~]$ 


[vagrant@control ~]$ vmstat 1
procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 2  0 440320 213348     12 748712    2    9   164   397  425  287 13  3 84  0  0
 2  1 440320 201604     12 751284    0    0  2508  1156 3475 1967 25  7 67  1  0
 2  0 440320 182640     12 752116    0    0   916    26 4149 1773 39  9 52  1  0
 2  0 440320 186440     12 752800    0    0   692    72 3376 1663 33  5 61  1  0
 4  0 440320 184704     12 752812    0    0     0   270 3459 2000 27  6 67  0  0
 2  0 440320 166272     12 753052    0    0    56    53 3814 1554 41  6 52  0  0
 2  0 440320 162864     12 753004    0    0     0  1210 3166 1867 31  5 64  0  0
 2  0 440320 151388     12 754352    0    0  1216    20 3615 1399 36  5 58  0  0
 1  0 440320 161224     12 754052    0    0    80   634 4544 1638 33  7 60  0  0
 1  2 440320 137180     12 761680    0    0  7320     8 3678 1792 28  8 62  3  0
 2  0 443392 137968     12 743380    0 3040  8608  3564 5945 1682 43  9 45  3  0
 2  0 443392 133388     12 745172    0    0  2688     0 3443 1544 38  5 56  1  0
 2  0 443392 149232     12 746232    0    0   872    54 4330 1513 35  7 58  1  0
 2  0 443392 130172     12 746328    0    0   344  1330 4548 2177 32  9 58  0  0
^C
[vagrant@control ~]$ 

30분째 돌고 있다.

* again from 

ssh 로그인도 안된다. control

TASK [rsyslog_client : Write rsyslog config for converting logs into syslog messages] *******************************
Saturday 27 July 2019  01:55:46 +0900 (0:00:09.138)       0:44:58.925 ********* 

virtualbox에서 붙으려 한다.
control login: root
[x.x] Out of memory: Kill proces 14818 (mysqld) score 74 or sacrifice child
[x.x] Killed process 14818 (mysqld) 

top - 02:04:44 up  4:39,  1 user,  load average: 57.54, 100.26, 57.39
Tasks: 625 total,   2 running, 623 sleeping,   0 stopped,   0 zombie
%Cpu(s): 27.2 us,  4.0 sy,  0.0 ni, 64.6 id,  3.0 wa,  0.0 hi,  1.2 si,  0.0 st
KiB Mem :  8008928 total,   126948 free,  7355084 used,   526896 buff/cache
KiB Swap:  1572860 total,        8 free,  1572852 used.   135696 avail Mem 

  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND                                                              
 3697 neutron   20   0  333168  68112   6408 R  99.7  0.9   0:06.19 neutron-linuxbr     


TASK [Create DB for service] ****************************************************************************************
Saturday 27 July 2019  02:04:08 +0900 (0:00:00.268)       0:53:20.255 ********* 
fatal: [infra1_horizon_container-280f6f5a]: FAILED! => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false, "failed": true}

PLAY RECAP **********************************************************************************************************
compute1                   : ok=162  changed=66   unreachable=0    failed=0   
infra1                     : ok=71   changed=38   unreachable=0    failed=0   
infra1_cinder_api_container-179eba5a : ok=78   changed=1    unreachable=0    failed=0   
infra1_glance_container-9e87261d : ok=67   changed=2    unreachable=0    failed=0   
infra1_heat_api_container-1e3d12d9 : ok=82   changed=54   unreachable=0    failed=0   
infra1_horizon_container-280f6f5a : ok=10   changed=4    unreachable=0    failed=1   
infra1_keystone_container-3c65c331 : ok=103  changed=6    unreachable=0    failed=0   
infra1_neutron_server_container-47a7eec0 : ok=77   changed=48   unreachable=0    failed=0   
infra1_nova_api_container-758f0659 : ok=95   changed=13   unreachable=0    failed=0   
localhost                  : ok=0    changed=0    unreachable=0    failed=0   
storage1                   : ok=50   changed=1    unreachable=0    failed=0   

Saturday 27 July 2019  02:04:11 +0900 (0:00:02.875)       0:53:23.131 ********* 
=============================================================================== 
rsyslog_client : Write rsyslog config for converting logs into syslog messages ----------------------------- 469.70s
os_neutron : Install neutron role packages ------------------------------------------------------------------ 84.38s
os_neutron : Install neutron role packages ------------------------------------------------------------------ 55.38s
os_neutron : Copy neutron rootwrap filters ------------------------------------------------------------------ 42.18s
os_neutron : Copy neutron rootwrap filters ------------------------------------------------------------------ 36.62s
Execute service action -------------------------------------------------------------------------------------- 35.25s
Ensure rabbitmq user ---------------------------------------------------------------------------------------- 33.62s
os_heat : Install requires pip packages --------------------------------------------------------------------- 31.56s
os_neutron : Install requires pip packages ------------------------------------------------------------------ 29.48s
os_nova : Compile new SELinux policy ------------------------------------------------------------------------ 28.90s
os_nova : Perform a cell_v2 discover ------------------------------------------------------------------------ 27.59s
Perform online data migrations ------------------------------------------------------------------------------ 24.39s
os_nova : Create the cell1 mapping entry in the nova API DB ------------------------------------------------- 23.65s
os_nova : Create the cell0 mapping entry in the nova API DB ------------------------------------------------- 23.47s
os_neutron : Perform a DB expand ---------------------------------------------------------------------------- 23.17s
os_nova : Synchronize the nova DB schema -------------------------------------------------------------------- 22.99s
os_neutron : Unarchive pre-built venv ----------------------------------------------------------------------- 22.84s
os_nova : Synchronize the nova API DB schema ---------------------------------------------------------------- 22.84s
os_heat : Install distro packages --------------------------------------------------------------------------- 22.19s
os_nova : Stop services ------------------------------------------------------------------------------------- 19.86s

EXIT NOTICE [Playbook execution failure] **************************************
===============================================================================
[root@deployer playbooks]# 
[root@deployer playbooks]# 

* again

- rpmdb broken again

#+BEGIN_SRC 
rm -f /var/lib/rpm/__db.00*
rpm --rebuilddb
#+END_SRC

- since the beginning, openstack-ansible setup-host.yml at playbook

#+BEGIN_SRC 
cd /opt/openstack-ansible/playbook/
openstack-ansible setup-host.yml
#+END_SRC

* with playbook setup-host something

TASK [lxc_hosts : Ensure image has been pre-staged] *****************************************************************************************************************************************************************************************
Monday 29 July 2019  11:12:02 +0900 (0:00:01.081)       0:05:12.154 ***********
fatal: [infra1]: FAILED! => {"ansible_job_id": "559411145086.25886", "attempts": 1, "changed": true, "cmd": "
aria2c --max-connection-per-server=4 --allow-overwrite=true --dir=/tmp --out=rootfs.tar.xz --check-certificate=true https://us.images.linuxcontainers.org/images/centos/7/amd64/default/20190728_07:08/rootfs.tar.xz https://uk.images.linuxcontainers.org/images/centos/7/amd64/default/20190728_07:08/rootfs.tar.xz  > /var/log/aria2c-image-prestage.log 2>&1", "delta": "0:00:01.482925", "end": "2019-07-29 11:10:56.046070", "failed": true, "finished": 1, "msg": "non-zero return code", "rc": 1, "start": "2019-07-29 11:10:54.563145", "stderr": "", "stderr_lines": [], "stdout": "", "stdout_lines": []}

aria2c again 

ls /tmp/rootfs*
rm /tmp/rootfs*

명령어만을 따로 추출하여 시도하였다. 실패?
/tmp의 rootfs* 파일을 삭제하고 다시 시도하였다. 성공!
openstack-ansible setup-host.yml 
again

잘 될것 같다.

실패는 성공의 어머니라고들 이야기한다.
실패하지 않으면 알 수 없다. 속을 알 수 없다.
실패하고 실패하고 그렇게 하면 속을 이해하게 된다.

aria2c를 사용하는 군요. 병렬전송 관련 전송이다. 아이서브 시절 확인하였다. 여기서 다시 보게 된다. 좋다. 하오. 好

지나갔다. 5분이 지났다. 다음 단계를 진행하고 있다. 헌하오. 

* control > high load of neutron-linuxbr rel
* DONE host done

PLAY RECAP **********************************************************************************************************************************************************************************************************************************compute1                   : ok=50   changed=2    unreachable=0    failed=0
infra1                     : ok=138  changed=27   unreachable=0    failed=0
infra1_cinder_api_container-179eba5a : ok=68   changed=6    unreachable=0    failed=0
infra1_galera_container-5103f3b8 : ok=68   changed=6    unreachable=0    failed=0
infra1_glance_container-9e87261d : ok=68   changed=6    unreachable=0    failed=0
infra1_heat_api_container-1e3d12d9 : ok=68   changed=6    unreachable=0    failed=0
infra1_horizon_container-280f6f5a : ok=78   changed=6    unreachable=0    failed=0
infra1_keystone_container-3c65c331 : ok=68   changed=6    unreachable=0    failed=0
infra1_memcached_container-21e6d45f : ok=68   changed=6    unreachable=0    failed=0
infra1_neutron_server_container-47a7eec0 : ok=68   changed=6    unreachable=0    failed=0
infra1_nova_api_container-758f0659 : ok=68   changed=6    unreachable=0    failed=0
infra1_rabbit_mq_container-76ec7893 : ok=71   changed=6    unreachable=0    failed=0
infra1_repo_container-a2b512e9 : ok=68   changed=6    unreachable=0    failed=0
infra1_utility_container-8de920e2 : ok=68   changed=6    unreachable=0    failed=0
storage1                   : ok=40   changed=2    unreachable=0    failed=0

Monday 29 July 2019  11:46:50 +0900 (0:00:02.102)       0:26:03.998 ***********
===============================================================================
openstack_hosts : Add requirement packages (repositories gpg keys packages, toolkits...) ------------------------------------------------------------------------------------------------------------------------------------------- 179.04s
lxc_hosts : Ensure that the LXC cache has been prepared ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------- 118.12s
lxc_container_create : Write default container config ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- 78.57s
lxc_hosts : Place container rootfs -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- 66.91s
lxc_container_create : Container service directories -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- 37.07s
lxc_hosts : Create lxc image -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- 28.49s
lxc_hosts : Ensure createrepo package is installed ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- 26.87s
lxc_container_create : Run container veth wiring script ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------- 24.74s
openstack_hosts : Adding new system tuning ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ 23.75s
lxc_container_create : Read custom facts from previous runs ------------------------------------------------------------------------------------------------------------------------------------------------------------------------- 22.40s
openstack_hosts : Load kernel module(s) --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- 21.58s
lxc_container_create : Gather variables for each operating system ------------------------------------------------------------------------------------------------------------------------------------------------------------------- 21.40s
lxc_container_create : LXC host config for container networks ----------------------------------------------------------------------------------------------------------------------------------------------------------------------- 20.58s
lxc_container_create : Defines a pre and post hook script --------------------------------------------------------------------------------------------------------------------------------------------------------------------------- 20.55s
pip_install : Install PIP ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- 19.98s
lxc_container_create : LXC autodev setup -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- 18.78s
lxc_container_create : Drop veth cleanup script ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- 17.68s
openstack_hosts : If a keyfile is provided, copy the gpg keyfile to the key location ------------------------------------------------------------------------------------------------------------------------------------------------ 16.58s
lxc_container_create : Create wiring script ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- 15.70s
openstack_hosts : Drop hosts file entries script locally ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------- 13.80s

EXIT NOTICE [Playbook execution success] **************************************
===============================================================================

* DONE setup-infrastructure.yml again takes 15m 

PLAY RECAP **********************************************************************************************************************************************************************************************************************************
compute1                   : ok=18   changed=0    unreachable=0    failed=0
infra1                     : ok=48   changed=0    unreachable=0    failed=0
infra1_cinder_api_container-179eba5a : ok=9    changed=0    unreachable=0    failed=0
infra1_galera_container-5103f3b8 : ok=74   changed=4    unreachable=0    failed=0
infra1_glance_container-9e87261d : ok=9    changed=0    unreachable=0    failed=0
infra1_heat_api_container-1e3d12d9 : ok=9    changed=0    unreachable=0    failed=0
infra1_horizon_container-280f6f5a : ok=9    changed=0    unreachable=0    failed=0
infra1_keystone_container-3c65c331 : ok=9    changed=0    unreachable=0    failed=0
infra1_memcached_container-21e6d45f : ok=35   changed=3    unreachable=0    failed=0
infra1_neutron_server_container-47a7eec0 : ok=9    changed=0    unreachable=0    failed=0
infra1_nova_api_container-758f0659 : ok=9    changed=0    unreachable=0    failed=0
infra1_rabbit_mq_container-76ec7893 : ok=67   changed=7    unreachable=0    failed=0
infra1_repo_container-a2b512e9 : ok=143  changed=5    unreachable=0    failed=0
infra1_utility_container-8de920e2 : ok=32   changed=2    unreachable=0    failed=0
localhost                  : ok=2    changed=1    unreachable=0    failed=0
storage1                   : ok=9    changed=0    unreachable=0    failed=0

Monday 29 July 2019  12:04:05 +0900 (0:00:06.088)       0:15:54.084 ***********
===============================================================================
haproxy_server : Create haproxy service config files -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- 56.62s
rabbitmq_server : Lock package versions --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- 28.66s
pip_install : Install PIP ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- 22.72s
repo_build : Create venv build options files ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- 22.27s
haproxy_server : Remove haproxy service config files for absent services ------------------------------------------------------------------------------------------------------------------------------------------------------------ 15.65s
memcached_server : Install distro packages ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ 14.83s
repo_build : Install packages ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- 14.24s
Load local packages ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- 14.18s
galera_server : Apply systemd options ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- 13.00s
pip_install : Drop pip config ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- 12.43s
Install pip packages ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- 12.24s
pip_install : Determine PIP installation script ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- 11.58s
repo_server : Git service data folder setup ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- 11.24s
pip_install : Create pip config directory ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- 11.12s
galera_server : Create galera users ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- 10.39s
haproxy_server : Install HAProxy Packages -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- 9.93s
Gathering Facts ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- 9.70s
galera_server : Install percona repo ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- 9.31s
pip_install : Install distro packages ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ 9.16s
repo_server : Drop NGINX configuration files ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- 8.55s

EXIT NOTICE [Playbook execution success] **************************************

* setup-openstack.yml ing
** pstree of control

#+BEGIN_SRC
systemd-+-VBoxService---7*[{VBoxService}]
        |-agetty
        |-auditd---{auditd}
        |-chronyd
        |-crond
        |-dbus-daemon---{dbus-daemon}
        |-dhclient
        |-dnsmasq
        |-gssproxy---5*[{gssproxy}]
        |-haproxy-systemd---haproxy---haproxy
        |-irqbalance
        |-lvmetad
        |-14*[lxc-autostart---systemd-+-5*[agetty]]
        |                             |-crond]
        |                             |-dbus-daemon]
        |                             |-dhclient]
        |                             |-rsyslogd---2*[{rsyslogd}]]
        |                             |-sshd]
        |                             |-systemd-journal]
        |                             `-systemd-logind]
        |-lxc-autostart---systemd-+-5*[agetty]
        |                         |-crond
        |                         |-dbus-daemon
        |                         |-dhclient
        |                         |-mysqld---70*[{mysqld}]
        |                         |-rsyslogd---4*[{rsyslogd}]
        |                         |-sshd
        |                         |-systemd-journal
        |                         |-systemd-logind
        |                         `-xinetd
        |-lxc-autostart---systemd-+-5*[agetty]
        |                         |-crond
        |                         |-dbus-daemon
        |                         |-dhclient
        |                         |-nginx---4*[nginx]
        |                         |-rsyslogd---4*[{rsyslogd}]
        |                         |-sshd
        |                         |-systemd-journal
        |                         |-systemd-logind
        |                         `-2*[uwsgi---9*[uwsgi]]
        |-lxc-autostart---systemd-+-5*[agetty]
        |                         |-beam.smp-+-erl_child_setup---inet_gethost---inet_gethost
        |                         |          `-135*[{beam.smp}]
        |                         |-crond
        |                         |-dbus-daemon
        |                         |-dhclient
        |                         |-epmd
        |                         |-rsyslogd---4*[{rsyslogd}]
        |                         |-sshd
        |                         |-systemd-journal
        |                         `-systemd-logind
        |-lxc-autostart---systemd-+-5*[agetty]
        |                         |-crond
        |                         |-dbus-daemon
        |                         |-dhclient
        |                         |-nova-conductor---2*[nova-conductor]
        |                         |-nova-consoleaut
        |                         |-nova-scheduler
        |                         |-nova-spicehtml5
        |                         |-rsyslogd---4*[{rsyslogd}]
        |                         |-sshd
        |                         |-systemd-journal
        |                         |-systemd-logind
        |                         `-3*[uwsgi---9*[uwsgi]]
        |-lxc-autostart---systemd-+-5*[agetty]
        |                         |-cinder-schedule
        |                         |-crond
        |                         |-dbus-daemon
        |                         |-dhclient
        |                         |-gssproxy---5*[{gssproxy}]
        |                         |-rpcbind
        |                         |-rsyslogd---4*[{rsyslogd}]
        |                         |-sshd
        |                         |-systemd-journal
        |                         |-systemd-logind
        |                         `-uwsgi---9*[uwsgi]
        |-lxc-autostart---systemd-+-5*[agetty]
        |                         |-crond
        |                         |-dbus-daemon
        |                         |-dhclient
        |                         |-gssproxy---5*[{gssproxy}]
        |                         |-rpcbind
        |                         |-rsyslogd---4*[{rsyslogd}]
        |                         |-sshd
        |                         |-systemd-journal
        |                         |-systemd-logind
        |                         `-uwsgi---8*[uwsgi]
        |-lxc-autostart---systemd-+-5*[agetty]
        |                         |-crond
        |                         |-dbus-daemon
        |                         |-dhclient
        |                         |-heat-engine---2*[heat-engine]
        |                         |-rsyslogd---4*[{rsyslogd}]
        |                         |-sshd
        |                         |-systemd-journal
        |                         |-systemd-logind
        |                         `-2*[uwsgi---8*[uwsgi]]
        |-lxc-autostart---systemd-+-5*[agetty]
        |                         |-crond
        |                         |-dbus-daemon
        |                         |-dhclient
        |                         |-memcached---9*[{memcached}]
        |                         |-rsyslogd---3*[{rsyslogd}]
        |                         |-sshd
        |                         |-systemd-journal
        |                         `-systemd-logind
        |-lxc-autostart---systemd-+-5*[agetty]
        |                         |-crond
        |                         |-dbus-daemon
        |                         |-dhclient
        |                         |-neutron-server---5*[neutron-server]
        |                         |-rsyslogd---4*[{rsyslogd}]
        |                         |-sshd
        |                         |-systemd-journal
        |                         `-systemd-logind
        |-lxc-autostart---systemd-+-5*[agetty]
        |                         |-crond
        |                         |-dbus-daemon
        |                         |-dhclient
        |                         |-nginx---2*[nginx]
        |                         |-pypi-server---239*[{pypi-server}]
        |                         |-rsync
        |                         |-rsyslogd---4*[{rsyslogd}]
        |                         |-sshd
        |                         |-systemd-journal
        |                         `-systemd-logind
        |-master-+-pickup
        |        `-qmgr
        |-neutron-dhcp-ag
        |-neutron-l3-agen
        |-neutron-linuxbr
        |-neutron-metadat---2*[neutron-metadat]
        |-neutron-meterin
        |-polkitd---6*[{polkitd}]
        |-privsep-helper
        |-rpcbind
        |-rsyslogd---5*[{rsyslogd}]
        |-sshd-+-sshd---sshd---bash---sudo---bash-+-less
        |      |                                  `-pstree
        |      `-sshd---lxc-attach---su---sh---python---python
        |-systemd-journal
        |-systemd-logind
        |-systemd-machine
        |-systemd-udevd
        `-tuned---4*[{tuned}]
#+END_SRC

** pstree of compute

#+BEGIN_SRC 
systemd(1)-+-VBoxService(820)-+-{VBoxService}(821)
           |                  |-{VBoxService}(822)
           |                  |-{VBoxService}(823)
           |                  |-{VBoxService}(824)
           |                  |-{VBoxService}(825)
           |                  |-{VBoxService}(826)
           |                  `-{VBoxService}(827)
           |-agetty(1605)
           |-auditd(622)---{auditd}(623)
           |-chronyd(668)
           |-crond(1597)
           |-dbus-daemon(660)---{dbus-daemon}(686)
           |-dhclient(1040)
           |-gssproxy(670)-+-{gssproxy}(675)
           |               |-{gssproxy}(676)
           |               |-{gssproxy}(677)
           |               |-{gssproxy}(678)
           |               `-{gssproxy}(679)
           |-irqbalance(650)
           |-ksmtuned(710)---sleep(17328)
           |-libvirtd(1591)-+-{libvirtd}(1614)
           |                |-{libvirtd}(1615)
           |                |-{libvirtd}(1616)
           |                |-{libvirtd}(1617)
           |                |-{libvirtd}(1618)
           |                |-{libvirtd}(1619)
           |                |-{libvirtd}(1620)
           |                |-{libvirtd}(1621)
           |                |-{libvirtd}(1622)
           |                |-{libvirtd}(1623)
           |                |-{libvirtd}(1628)
           |                |-{libvirtd}(1629)
           |                |-{libvirtd}(1630)
           |                |-{libvirtd}(1631)
           |                |-{libvirtd}(1632)
           |                `-{libvirtd}(1645)
           |-lvmetad(471)
           |-master(1915)-+-pickup(13700)
           |              `-qmgr(1919)
           |-neutron-linuxbr(17417)
           |-nova-compute(1634)
           |-polkitd(648)-+-{polkitd}(685)
           |              |-{polkitd}(687)
           |              |-{polkitd}(689)
           |              |-{polkitd}(690)
           |              |-{polkitd}(692)
           |              `-{polkitd}(694)
           |-rpcbind(684)
           |-rsyslogd(1585)-+-{rsyslogd}(1598)
           |                |-{rsyslogd}(1599)
           |                |-{rsyslogd}(1600)
           |                `-{rsyslogd}(1602)
           |-sshd(1587)---sshd(17384)---sshd(17388)---bash(17389)---pstree(17426)
           |-systemd-journal(452)
           |-systemd-logind(652)
           |-systemd-machine(649)
           |-systemd-udevd(486)
           `-tuned(1581)-+-{tuned}(1815)
                         |-{tuned}(1816)
                         |-{tuned}(1818)
                         `-{tuned}(1852)
#+END_SRC

** pstree of storage

#+BEGIN_SRC 
[vagrant@storage ~]$ pstree -p
systemd(1)-+-VBoxService(804)-+-{VBoxService}(805)
           |                  |-{VBoxService}(806)
           |                  |-{VBoxService}(807)
           |                  |-{VBoxService}(808)
           |                  |-{VBoxService}(809)
           |                  |-{VBoxService}(810)
           |                  `-{VBoxService}(811)
           |-agetty(1592)
           |-auditd(646)---{auditd}(647)
           |-chronyd(687)
           |-cinder-volume(7467)---cinder-volume(7594)
           |-crond(1589)
           |-dbus-daemon(679)---{dbus-daemon}(702)
           |-dhclient(1024)
           |-gssproxy(689)-+-{gssproxy}(694)
           |               |-{gssproxy}(695)
           |               |-{gssproxy}(696)
           |               |-{gssproxy}(697)
           |               `-{gssproxy}(698)
           |-irqbalance(678)
           |-master(1831)-+-pickup(6600)
           |              `-qmgr(1833)
           |-polkitd(703)-+-{polkitd}(725)
           |              |-{polkitd}(726)
           |              |-{polkitd}(727)
           |              |-{polkitd}(728)
           |              |-{polkitd}(729)
           |              `-{polkitd}(730)
           |-rpcbind(692)
           |-rsyslogd(1573)-+-{rsyslogd}(1580)
           |                |-{rsyslogd}(1581)
           |                |-{rsyslogd}(1582)
           |                `-{rsyslogd}(1583)
           |-sshd(1572)---sshd(7811)---sshd(7815)---bash(7816)---pstree(7840)
           |-systemd-journal(449)
           |-systemd-logind(677)
           |-systemd-udevd(480)
           |-tgtd(1568)
           `-tuned(1570)-+-{tuned}(1768)
                         |-{tuned}(1769)
                         |-{tuned}(1770)
                         `-{tuned}(1791)
#+END_SRC
* DONE setup-openstack.yml done, this is the first time

PLAY RECAP **********************************************************************************************************************************************************************************************************************************compute1                   : ok=143  changed=8    unreachable=0    failed=0
infra1                     : ok=65   changed=9    unreachable=0    failed=0
infra1_cinder_api_container-179eba5a : ok=78   changed=1    unreachable=0    failed=0
infra1_glance_container-9e87261d : ok=67   changed=2    unreachable=0    failed=0
infra1_heat_api_container-1e3d12d9 : ok=71   changed=5    unreachable=0    failed=0
infra1_horizon_container-280f6f5a : ok=66   changed=45   unreachable=0    failed=0
infra1_keystone_container-3c65c331 : ok=103  changed=7    unreachable=0    failed=0
infra1_neutron_server_container-47a7eec0 : ok=60   changed=3    unreachable=0    failed=0
infra1_nova_api_container-758f0659 : ok=90   changed=9    unreachable=0    failed=0
infra1_utility_container-8de920e2 : ok=0    changed=0    unreachable=0    failed=0
localhost                  : ok=0    changed=0    unreachable=0    failed=0
storage1                   : ok=54   changed=5    unreachable=0    failed=0

Monday 29 July 2019  13:26:21 +0900 (0:00:00.027)       0:43:08.974 ***********
===============================================================================
os_horizon : Install distro packages ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ 96.83s
os_horizon : Ensure static files are collected and compressed ----------------------------------------------------------------------------------------------------------------------------------------------------------------------- 88.60s
os_nova : Stop services ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- 38.90s
os_nova : Perform a cell_v2 discover ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ 33.62s
os_horizon : Install requires pip packages ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ 31.87s
os_nova : Compile new SELinux policy ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ 27.99s
os_neutron : Copy neutron rootwrap filters ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ 27.21s
os_neutron : Copy neutron rootwrap filters ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ 25.84s
os_neutron : Stop services ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- 25.24s
os_nova : Create the cell1 mapping entry in the nova API DB ------------------------------------------------------------------------------------------------------------------------------------------------------------------------- 24.56s
os_nova : Install distro packages --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- 24.40s
os_nova : Synchronize the nova API DB schema ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- 24.05s
os_nova : Synchronize the nova DB schema -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- 23.70s
os_nova : Create the cell0 mapping entry in the nova API DB ------------------------------------------------------------------------------------------------------------------------------------------------------------------------- 22.89s
os_horizon : Enable project panels -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- 22.48s
os_glance : Deploy Glance configuration files --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- 20.70s
os_keystone : Create keystone dir --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- 20.15s
os_nova : Create tmpfiles.d entry --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- 17.56s
os_horizon : Unarchive pre-built venv ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- 15.08s
os_neutron : Check for available offline migrations --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- 14.69s

EXIT NOTICE [Playbook execution success] **************************************
===============================================================================
* DONE finally have to ing

lxc-ls | grep utility
lxc-attach -n infra1_utility_container-x
openstack user list --os-cloud=default

Verifying the Dashboard (horizon)

    With a web browser, access the Dashboard by using the external load balancer IP address 
defined by the external_lb_vip_address option 
in the /etc/openstack_deploy/openstack_user_config.yml file. 

The Dashboard uses HTTPS on port 443.
    Authenticate by using the admin user name and the password 
defined by the keystone_auth_admin_password option 
in the /etc/openstack_deploy/user_secrets.yml file.

? cat /etc/openstack_deploy/openstack_user_config.yml | grep external
  # The internal and external VIP should be different IPs, however they
  external_lb_vip_address: 172.29.236.10

? cat /etc/openstack_deploy/user_secrets.yml | grep keystone_auth
keystone_auth_admin_password: 29f84426adc7f7422fb908d7b2fab8a9891d64d658ebd8dd3132c3aea8

#+BEGIN_SRC 
? lxc-attach -n `lxc-ls | grep utility | awk '{ print $2 }'`
? openstack --os-cloud=default user list
+----------------------------------+--------------------+
| ID                               | Name               |
+----------------------------------+--------------------+
| 149130286a804eb1884b074fdb2fdbc4 | neutron            |
| 4bc224ccfa354dc19f9a6adfb567778a | admin              |
| 609b3f4166e246fba556074c3fb95031 | glance             |
| 6696f97c04e843a4a6c245fc3d72cbc3 | stack_domain_admin |
| 823152811ec545728f7f3b98da3c7751 | placement          |
| 98fa801365d049d5b8ed1d2068240417 | keystone           |
| 99a7131c666842039d8c291ec70d9707 | nova               |
| b423ca56c73c47dbbc030f6e0482f73f | heat               |
| b5466f1bedc24633ac122750e5bde5a7 | cinder             |
+----------------------------------+--------------------+
?
#+END_SRC

cinder rel and other command not working as I'm expected so dig it.
- [X] try download python2-openstackclient from control(infra1)

#+BEGIN_SRC 
yum install python2-openstackclient -y
#+END_SRC

[root@control ~]# lxc-ls -1 | grep util | tail -1
infra1_utility_container-8de920e2
[root@control ~]# lxc-attach -n `lxc-ls -1 | grep util | tail -1`
[root@infra1-utility-container-8de920e2 ~]# . openrc
[root@infra1-utility-container-8de920e2 ~]# cinder service-list
+------------------+--------------------------------------+------+---------+-------+----------------------------+-----------------+
| Binary           | Host                                 | Zone | Status  | State | Updated_at                 | Disabled Reason |
+------------------+--------------------------------------+------+---------+-------+----------------------------+-----------------+
| cinder-scheduler | infra1-cinder-api-container-179eba5a | nova | enabled | up    | 2019-07-29T06:04:02.000000 | -               |
| cinder-volume    | storage@lvm                          | nova | enabled | down  | 2019-07-29T03:53:00.000000 | -               |
+------------------+--------------------------------------+------+---------+-------+----------------------------+-----------------+
[root@infra1-utility-container-8de920e2 ~]#


[root@infra1-utility-container-8de920e2 ~]# openstack compute service list
+----+------------------+------------------------------------+----------+---------+-------+----------------------------+
| ID | Binary           | Host                               | Zone     | Status  | State | Updated At                 |
+----+------------------+------------------------------------+----------+---------+-------+----------------------------+
|  1 | nova-scheduler   | infra1-nova-api-container-758f0659 | internal | enabled | up    | 2019-07-29T06:05:56.000000 |
|  2 | nova-consoleauth | infra1-nova-api-container-758f0659 | internal | enabled | up    | 2019-07-29T06:05:56.000000 |
|  3 | nova-conductor   | infra1-nova-api-container-758f0659 | internal | enabled | up    | 2019-07-29T06:05:56.000000 |
+----+------------------+------------------------------------+----------+---------+-------+----------------------------+
x
so it works

* DONE arch of this vm based trying

- vm using virtualbox
- add two more network interface using cli

** TODO tbl

| nic  | vm network Attached to                   | bridge     | x  |        deployer | control | compute | storage | note |
|------+------------------------------------------+------------+----+-----------------+---------+---------+---------+------|
| eth0 | NAT                                      |            |    |       10.0.2.15 | t       |       t |       t |      |
| eth1 | VirtualBox Host-Only Ethernet Adapter #1 |            | A2 | 192.168.100.101 | 102     |     103 |     104 |      |
| eth2 | #2                                       | br-mgmt    | A3 |    172.29.236.3 | 10, 11  |      12 |      13 |      |
| eth3 | #3                                       | br-storage | A4 |    172.29.244.3 | 11      |      12 |      13 |      |
| eth4 | #4                                       | br-vxlan   | A5 |    172.29.240.3 | 11      |      12 |      13 |      |
| eth5 | #5                                       | br-vlan    | A6 |               x | x       |       x |       x |      |

** DONE interfaces of ifcfg-x of control's br-mgmt rel

? hostname
control

? cat "ifcfg-br-mgmt:0"
NM_CONTROLLED=no
DEVICE=br-mgmt:0
ONBOOT=yes
BOOTPROTO=static
IPADDR=172.29.236.10
PREFIX=22
?

** DONE interfaces or ifcfg-x

==> ifcfg-eth0 <==
DEVICE="eth0"
BOOTPROTO="dhcp"
ONBOOT="yes"
TYPE="Ethernet"
PERSISTENT_DHCLIENT="yes"

==> ifcfg-eth1 <==
NM_CONTROLLED=yes
BOOTPROTO=none
ONBOOT=yes
IPADDR=192.168.100.101
NETMASK=255.255.255.0
DEVICE=eth1
PEERDNS=no

==> ifcfg-eth2 <==
NM_CONTROLLED=no
TYPE=Ethernet
BOOTPROTO=none
ONBOOT=yes
DEVICE=eth2
BRIDGE=br-mgmt

==> ifcfg-br-mgmt <==
BOOTPROTO=none
ONBOOT=yes
DEVICE=br-mgmt
TYPE=Bridge
IPADDR=172.29.236.3
PREFIX=22

==> ifcfg-eth3 <==
NM_CONTROLLED=no
TYPE=Ethernet
BOOTPROTO=none
ONBOOT=yes
DEVICE=eth3
BRIDGE=br-storage

==> ifcfg-br-storage <==
BOOTPROTO=none
ONBOOT=yes
DEVICE=br-storage
TYPE=Bridge
IPADDR=172.29.244.3
PREFIX=22

==> ifcfg-eth4 <==
NM_CONTROLLED=no
TYPE=Ethernet
BOOTPROTO=none
ONBOOT=yes
DEVICE=eth4
BRIDGE=br-vxlan

==> ifcfg-br-vxlan <==
BOOTPROTO=none
ONBOOT=yes
DEVICE=br-vxlan
TYPE=Bridge
IPADDR=172.29.240.3
PREFIX=22

==> ifcfg-eth5 <==
NM_CONTROLLED=no
TYPE=Ethernet
BOOTPROTO=none
ONBOOT=yes
DEVICE=eth5
BRIDGE=br-vlan

==> ifcfg-br-vlan <==
BOOTPROTO=none
ONBOOT=yes
DEVICE=br-vlan
TYPE=Bridge
* TODO 20190802 infra then fail at haproxy

RUNNING HANDLER [haproxy_endpoints : Set haproxy service state] *************************************************************************************************************
Friday 02 August 2019  15:58:22 +0900 (0:00:00.568)       0:49:35.453 ********* 
failed: [infra1_galera_container-3034b496 -> 10.74.41.101] (item=infra1) => {"changed": false, "failed": true, "item": "infra1", "module_stderr": "Shared connection to 10.74.41.101 closed.\r\n", "module_stdout": "Traceback (most recent call last):\r\n  File \"/tmp/ansible_QKwuNq/ansible_module_haproxy.py\", line 458, in <module>\r\n    main()\r\n  File \"/tmp/ansible_QKwuNq/ansible_module_haproxy.py\", line 454, in main\r\n    ansible_haproxy.act()\r\n  File \"/tmp/ansible_QKwuNq/ansible_module_haproxy.py\", line 403, in act\r\n    state_before = self.get_state_for(self.backend, self.host)\r\n  File \"/tmp/ansible_QKwuNq/ansible_module_haproxy.py\", line 334, in get_state_for\r\n    data = self.execute('show stat', 200, False).lstrip('# ')\r\n  File \"/tmp/ansible_QKwuNq/ansible_module_haproxy.py\", line 254, in execute\r\n    self.client.connect(self.socket)\r\n  File \"/usr/lib64/python2.7/socket.py\", line 224, in meth\r\n    return getattr(self._sock,name)(*args)\r\nsocket.error: [Errno 111] Connection refused\r\n", "msg": "MODULE FAILURE", "rc": 0}

PLAY RECAP ******************************************************************************************************************************************************************
compute1                   : ok=18   changed=0    unreachable=0    failed=0   
infra1                     : ok=52   changed=22   unreachable=0    failed=0   
infra1_cinder_api_container-bb74c95f : ok=9    changed=0    unreachable=0    failed=0   
infra1_galera_container-3034b496 : ok=66   changed=31   unreachable=0    failed=2   
infra1_glance_container-bd2b368f : ok=9    changed=0    unreachable=0    failed=0   
infra1_heat_api_container-9b9e7300 : ok=9    changed=0    unreachable=0    failed=0   
infra1_horizon_container-848b63f4 : ok=9    changed=0    unreachable=0    failed=0   
infra1_keystone_container-8b8b3f8a : ok=9    changed=0    unreachable=0    failed=0   
infra1_memcached_container-0d293730 : ok=40   changed=19   unreachable=0    failed=0   
infra1_neutron_server_container-cc70c1ea : ok=9    changed=0    unreachable=0    failed=0   
infra1_nova_api_container-11e90b9f : ok=9    changed=0    unreachable=0    failed=0   
infra1_rabbit_mq_container-13634058 : ok=9    changed=0    unreachable=0    failed=0   
infra1_repo_container-044e96f3 : ok=176  changed=75   unreachable=0    failed=0   
infra1_utility_container-71f5b32c : ok=36   changed=17   unreachable=0    failed=0   
localhost                  : ok=2    changed=1    unreachable=0    failed=0   
storage1                   : ok=9    changed=0    unreachable=0    failed=0   

Friday 02 August 2019  15:58:25 +0900 (0:00:02.461)       0:49:37.915 ********* 
=============================================================================== 
repo_build : Create OpenStack-Ansible requirement wheels ----------------------------------------------------------------------------------------------------------- 955.97s
repo_build : Clone git repositories -------------------------------------------------------------------------------------------------------------------------------- 574.56s
repo_build : Wait for the venvs builds to complete ----------------------------------------------------------------------------------------------------------------- 283.96s
galera_server : Install galera_server role remote packages --------------------------------------------------------------------------------------------------------- 133.06s
Get list of python clients ----------------------------------------------------------------------------------------------------------------------------------------- 127.83s
repo_build : Install packages --------------------------------------------------------------------------------------------------------------------------------------- 58.67s
galera_client : Install galera distro packages ---------------------------------------------------------------------------------------------------------------------- 45.97s
haproxy_server : Create haproxy service config files ---------------------------------------------------------------------------------------------------------------- 43.62s
galera_client : Install galera distro packages ---------------------------------------------------------------------------------------------------------------------- 36.10s
repo_server : Install distro packages ------------------------------------------------------------------------------------------------------------------------------- 35.38s
repo_build : Execute the venv build scripts asynchonously ----------------------------------------------------------------------------------------------------------- 27.37s
repo_build : Create venv build options files ------------------------------------------------------------------------------------------------------------------------ 22.73s
galera_server : Start new cluster ----------------------------------------------------------------------------------------------------------------------------------- 21.93s
memcached_server : Install distro packages -------------------------------------------------------------------------------------------------------------------------- 21.39s
galera_server : Install pip packages -------------------------------------------------------------------------------------------------------------------------------- 18.28s
pip_install : Install PIP ------------------------------------------------------------------------------------------------------------------------------------------- 17.58s
galera_server : Apply systemd options ------------------------------------------------------------------------------------------------------------------------------- 15.99s
Install pip packages ------------------------------------------------------------------------------------------------------------------------------------------------ 14.70s
haproxy_server : Install HAProxy Packages --------------------------------------------------------------------------------------------------------------------------- 14.57s
repo_server : Install pip packages (from repo) ---------------------------------------------------------------------------------------------------------------------- 13.87s

EXIT NOTICE [Playbook execution failure] **************************************
===============================================================================

[root@deployer openstack_deploy]# pwd
/etc/openstack_deploy
[root@deployer openstack_deploy]# diff openstack_user_config.yml.v1 openstack_user_config.yml
3,5c3,5
<   container: 10.74.41.0/22
<   tunnel: 10.74.44.0/22
<   storage: 10.74.42.0/22
---
>   container: 10.74.41.0/24
>   tunnel: 10.74.44.0/24
>   storage: 10.74.42.0/24
[root@deployer openstack_deploy]# 

- [ ] what I have to do after modify something

but work without

* TODO next setup-openstack with keystone, no_log

TASK [Create DB for service] **********************************************************************************************************************************************
Friday 02 August 2019  16:21:37 +0900 (0:00:00.053)       0:00:13.868 ********* 
fatal: [infra1_keystone_container-8b8b3f8a]: FAILED! => {"censored": "the output has been hidden due to the fact that 'no_log: true' was specified for this result", "changed": false, "failed": true}

NO MORE HOSTS LEFT ********************************************************************************************************************************************************

PLAY RECAP ************************************************************************************************************************************************************
infra1_keystone_container-8b8b3f8a : ok=2    changed=2    unreachable=0    failed=1   

Friday 02 August 2019  16:22:09 +0900 (0:00:32.385)       0:00:46.253 ********* 
=============================================================================== 
Create DB for service --------------------------------------------------------------------------------------------------------------------------------------------- 32.39s
Ensure rabbitmq user ----------------------------------------------------------------------------------------------------------------------------------------------- 7.69s
Ensure Rabbitmq vhost ---------------------------------------------------------------------------------------------------------------------------------------------- 5.94s
Ensure rabbitmq user ----------------------------------------------------------------------------------------------------------------------------------------------- 0.05s
Ensure Rabbitmq vhost ---------------------------------------------------------------------------------------------------------------------------------------------- 0.05s

EXIT NOTICE [Playbook execution failure] **************************************
===============================================================================
? openstack-ansible setup-openstack.yml

- [ ] openstack-ansible os-keystone-install.yml

? vi common-tasks/mysql-db-user.yml 

- [X] no_log to False

? openstack-ansible os-keystone-install.yml 

TASK [Create DB for service] **********************************************************************************************************************************************
Friday 02 August 2019  16:30:39 +0900 (0:00:00.053)       0:00:08.941 ********* 
fatal: [infra1_keystone_container-8b8b3f8a -> 10.74.40.20]: FAILED! => {"changed": false, "failed": true, "msg": "unable to connect to database, check login_user and login_password are correct or /root/.my.cnf has the credentials. Exception message: (2003, 'Can\\'t connect to MySQL server on \\'10.74.41.101\\' (110 \"Connection timed out\")')"}

do something about galera

* DONE mixed and mixed config

- only that or more
- only that, (swap control compute)
- or more, don not know that yet

* DONE broken some diff msg

rm -f /var/lib/rpm/__db*
rpm --rebuilddb
yum install createrepo -y
yum install lynx -y
* DONE network issue, enough

- atto, unstable wireless network
- office, illegal network? broken download or more failure eventually
- so, no way out
* DONE can not create volume so no vm : Block Device Mapping is invalid

- [2019-08-07 수] ^^
- so create 'cinder-volumes' on storage node, so much hard
  - trying: reduce /home mounted, umount, xfs_something, crash and more
  - allow to make pv at /dev/sda3 by edit some /etc/lvm/lvm.conf
- restart cinder container on control
  - attach to util
  - lxc-stop then lxc-start
- restart daemon on storage
  - systemd controlled, systemctl list-units | grep cinder
- chk using cli and horizon
  - cinder create 1

* DONE network network network, provider network or what

- webui and cli
#+BEGIN_SRC 
Name
    ext-net
ID
    047fbdbb-fbaa-4efc-bd5d-46f24913d27b
Project ID
    df15475f8fdc4d40a6b9460cfe514d2d
Status
    Active
Admin State
    UP
Shared
    Yes
External Network
    Yes
MTU
    1500
Provider Network
    Network Type: flat
    Physical Network: flat
    Segmentation ID: -
#+END_SRC
* TODO word(s), lxc rel
* TODO word, lvm
* TODO nav horizon, maybe first time
* TODO gen vm on horizon, status: error

- [2019-08-07 수] 

#+BEGIN_SRC 
[root@infra1-utility-container-6d08a42a ~]# openstack server create --image cirros --network pantech --flavor 2 --key-name tk example-instance
+-------------------------------------+-----------------------------------------------+
| Field                               | Value                                         |
+-------------------------------------+-----------------------------------------------+
| OS-DCF:diskConfig                   | MANUAL                                        |
| OS-EXT-AZ:availability_zone         |                                               |
| OS-EXT-SRV-ATTR:host                | None                                          |
| OS-EXT-SRV-ATTR:hypervisor_hostname | None                                          |
| OS-EXT-SRV-ATTR:instance_name       |                                               |
| OS-EXT-STS:power_state              | NOSTATE                                       |
| OS-EXT-STS:task_state               | scheduling                                    |
| OS-EXT-STS:vm_state                 | building                                      |
| OS-SRV-USG:launched_at              | None                                          |
| OS-SRV-USG:terminated_at            | None                                          |
| accessIPv4                          |                                               |
| accessIPv6                          |                                               |
| addresses                           |                                               |
| adminPass                           | nGQALqe7vbKT                                  |
| config_drive                        |                                               |
| created                             | 2019-08-07T06:45:14Z                          |
| flavor                              | m1.mini (2)                                   |
| hostId                              |                                               |
| id                                  | 9180d024-6fe8-40dd-99c9-6726df8b4efe          |
| image                               | cirros (cda0858b-876e-4858-b0f1-0ac14267e7e0) |
| key_name                            | tk                                            |
| name                                | example-instance                              |
| progress                            | 0                                             |
| project_id                          | df15475f8fdc4d40a6b9460cfe514d2d              |
| properties                          |                                               |
| security_groups                     | name='default'                                |
| status                              | BUILD                                         |
| updated                             | 2019-08-07T06:45:14Z                          |
| user_id                             | 472f0512eeb342edbe150bdc4735f69d              |
| volumes_attached                    |                                               |
+-------------------------------------+-----------------------------------------------+
[root@infra1-utility-container-6d08a42a ~]#

[root@infra1-utility-container-6d08a42a ~]# openstack server create --image cirros --network pantech --flavor 2 --key-name tk example-instance
+-------------------------------------+-----------------------------------------------+
| Field                               | Value                                         |
+-------------------------------------+-----------------------------------------------+
| OS-DCF:diskConfig                   | MANUAL                                        |
| OS-EXT-AZ:availability_zone         |                                               |
| OS-EXT-SRV-ATTR:host                | None                                          |
| OS-EXT-SRV-ATTR:hypervisor_hostname | None                                          |
| OS-EXT-SRV-ATTR:instance_name       |                                               |
| OS-EXT-STS:power_state              | NOSTATE                                       |
| OS-EXT-STS:task_state               | scheduling                                    |
| OS-EXT-STS:vm_state                 | building                                      |
| OS-SRV-USG:launched_at              | None                                          |
| OS-SRV-USG:terminated_at            | None                                          |
| accessIPv4                          |                                               |
| accessIPv6                          |                                               |
| addresses                           |                                               |
| adminPass                           | nGQALqe7vbKT                                  |
| config_drive                        |                                               |
| created                             | 2019-08-07T06:45:14Z                          |
| flavor                              | m1.mini (2)                                   |
| hostId                              |                                               |
| id                                  | 9180d024-6fe8-40dd-99c9-6726df8b4efe          |
| image                               | cirros (cda0858b-876e-4858-b0f1-0ac14267e7e0) |
| key_name                            | tk                                            |
| name                                | example-instance                              |
| progress                            | 0                                             |
| project_id                          | df15475f8fdc4d40a6b9460cfe514d2d              |
| properties                          |                                               |
| security_groups                     | name='default'                                |
| status                              | BUILD                                         |
| updated                             | 2019-08-07T06:45:14Z                          |
| user_id                             | 472f0512eeb342edbe150bdc4735f69d              |
| volumes_attached                    |                                               |
+-------------------------------------+-----------------------------------------------+
[root@infra1-utility-container-6d08a42a ~]#

[root@infra1-utility-container-6d08a42a ~]# openstack server list
+--------------------------------------+------------------+--------+----------+--------+---------+
| ID                                   | Name             | Status | Networks | Image  | Flavor  |
+--------------------------------------+------------------+--------+----------+--------+---------+
| 9180d024-6fe8-40dd-99c9-6726df8b4efe | example-instance | ERROR  |          | cirros | m1.mini |
| 914c36b1-9418-4a3f-8955-4748d84024ed | t again          | ERROR  |          |        | m1.mini |
| dd1acdb7-db0b-4820-8e23-3b140b59bd66 | t                | ERROR  |          |        | m1.mini |
+--------------------------------------+------------------+--------+----------+--------+---------+
#+END_SRC

#+BEGIN_SRC 
[root@control ~]# lxc-attach -n $(lxc-ls -1 | grep nova)
[root@infra1-nova-api-container-79a49546 ~]# cd /var/log/nova/
[root@infra1-nova-api-container-79a49546 nova]# ls
nova-api-metadata.log    nova-api-wsgi.log   nova-consoleauth.log  nova-metadata-wsgi.log  nova-scheduler.log
nova-api-os-compute.log  nova-conductor.log  nova-manage.log       nova-placement-api.log  nova-spicehtml5proxy.log
[root@infra1-nova-api-container-79a49546 nova]#
#+END_SRC

#+BEGIN_SRC 
[root@compute nova]# cat nova-compute.log  | less
[root@compute nova]# pwd 
/var/log/nova

2019-08-07 15:45:21.056 22812 ERROR nova.compute.manager [req-b0b8e45d-9ee6-4d6c-a54f-28f8d32a8ae6 472f0512eeb342edbe150bdc4735f69d df15475f8fdc4d40a6b9460cfe514d2d - default default] Instance failed network setup after 1 attempt(s): PortBindingFailed: Binding failed for port c7999dfd-46f5-4cda-91d0-40b8ea4c914f, please check neutron logs for more information.
2019-08-07 15:45:21.056 22812 ERROR nova.compute.manager Traceback (most recent call last):
2019-08-07 15:45:21.056 22812 ERROR nova.compute.manager   File "/openstack/venvs/nova-17.1.13.dev3/lib/python2.7/site-packages/nova/compute/manager.py", line 1436, in _allocate_network_async
2019-08-07 15:45:21.056 22812 ERROR nova.compute.manager     bind_host_id=bind_host_id)
2019-08-07 15:45:21.056 22812 ERROR nova.compute.manager   File "/openstack/venvs/nova-17.1.13.dev3/lib/python2.7/site-packages/nova/network/neutronv2/api.py", line 989, in allocate_for_instance
#+END_SRC

#+BEGIN_SRC 
[root@compute neutron]# tail neutron-linuxbridge-agent.log

2019-08-07 15:53:37.131 25169 INFO neutron.common.config [-] Logging enabled!
2019-08-07 15:53:37.131 25169 INFO neutron.common.config [-] /openstack/venvs/neutron-17.1.13.dev3/bin/neutron-linuxbridge-agent version 12.1.1.dev10                       2019-08-07 15:53:37.132 25169 INFO neutron.plugins.ml2.drivers.linuxbridge.agent.linuxbridge_neutron_agent [-] Interface mappings: {'flat': 'eth12', 'vlan': 'br-vlan'}
2019-08-07 15:53:37.132 25169 INFO neutron.plugins.ml2.drivers.linuxbridge.agent.linuxbridge_neutron_agent [-] Bridge mappings: {}
2019-08-07 15:53:37.142 25169 ERROR neutron.plugins.ml2.drivers.linuxbridge.agent.linuxbridge_neutron_agent [-] Interface eth12 for physical network flat does not exist. Agent terminated!
#+END_SRC

eth12 but br-vlan but type flat
